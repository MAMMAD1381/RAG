{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"mount_file_id":"1xGeaM-oFVeEliD38KtLRTtP4lPrQVkz-","authorship_tag":"ABX9TyMwjhevRLrIUxWm42iKQ2Kl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"XyuFSQGWlMrD"}},{"cell_type":"code","source":["!pip install -q chromadb sentence-transformers pymupdf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"xxPdB5Lm6zpx","executionInfo":{"status":"ok","timestamp":1717841846582,"user_tz":-210,"elapsed":151025,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"ac1ce7f0-26f5-4349-bf11-a9fae697c929"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.8/526.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m773.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n","weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!pip install -q chromadb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T8AWjbKsIDL4","executionInfo":{"status":"ok","timestamp":1717669405776,"user_tz":-210,"elapsed":36632,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"4bfe6c54-a4a6-42a2-a667-5850509509ba","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.8/526.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n","weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!pip install -q langchain\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bS6oQJeVSRTH","executionInfo":{"status":"ok","timestamp":1717609462111,"user_tz":-210,"elapsed":9225,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"43a7c35d-195a-4b0b-df15-076807ba03ee","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.2)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.4)\n","Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.1)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.71)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.2)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (1.33)\n","Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (23.2)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.18.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.3)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (2.4)\n"]}]},{"cell_type":"code","source":["from huggingface_hub import login\n","import logging\n","from transformers import (\n","    GPT2Tokenizer, GPT2LMHeadModel, T5Tokenizer, T5ForConditionalGeneration,\n","    BertTokenizer, BertForQuestionAnswering, DistilBertTokenizer, DistilBertForQuestionAnswering,\n","    GPTNeoForCausalLM, pipeline, AutoTokenizer, AutoModelForSeq2SeqLM, AutoModel, AutoModelForCausalLM,\n","    BartTokenizer, BartForConditionalGeneration, PegasusTokenizer, PegasusForConditionalGeneration\n",")\n","import torch\n","from chromadb import Client, Settings\n","from sentence_transformers import SentenceTransformer\n","import gc\n","import fitz"],"metadata":{"id":"mJQSWTpCxjb2","executionInfo":{"status":"ok","timestamp":1717841872194,"user_tz":-210,"elapsed":25617,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["project_path = '/content/drive/MyDrive/Colab Notebooks/RAG'"],"metadata":{"id":"5wT2fvm20bmm","executionInfo":{"status":"ok","timestamp":1717841872195,"user_tz":-210,"elapsed":6,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# GPU"],"metadata":{"id":"-51Pl889lKDn"}},{"cell_type":"code","source":["\n","print(torch.cuda.is_available())\n","# print(torch.cuda.get_device_name(0))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zd5YQ-IfoDFN","executionInfo":{"status":"ok","timestamp":1717841872195,"user_tz":-210,"elapsed":5,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"3c0a9f7d-ba0d-4bbb-f8d5-9737635047fb"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["False\n"]}]},{"cell_type":"markdown","source":["# Hugging Face Login"],"metadata":{"id":"dPnOa3oLlRy2"}},{"cell_type":"code","source":["# Log in using your Hugging Face access token\n","access_token = \"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\"\n","login(access_token)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6QvoS3g0665l","executionInfo":{"status":"ok","timestamp":1717841872676,"user_tz":-210,"elapsed":485,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"e62de715-0fa8-4cbc-c22d-a17b4369cdba"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: read).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}]},{"cell_type":"markdown","source":["# LLM\n","\n","\n","---\n","\n","###key functions of LLM class:\n","\n","\n","*   **load_llm_local**: tries to load an llm from google drvie\n","*   **load_llm_online**: loads the llm from hugging face\n","*   **select_device**: if gpu is available it will select it\n","*   **generate_text**: it can generate text based on given prompt"],"metadata":{"id":"_com4NubP5Jv"}},{"cell_type":"code","source":["class LLM:\n","    model_classes = {\n","        'gpt2': (GPT2Tokenizer, GPT2LMHeadModel, 'gpt2'),\n","        't5': (T5Tokenizer, T5ForConditionalGeneration, 't5-small'),\n","        'bert': (BertTokenizer, BertForQuestionAnswering, 'bert-large-uncased-whole-word-masking-finetuned-squad'),\n","        'distil-bert': (DistilBertTokenizer, DistilBertForQuestionAnswering, 'distilbert-base-cased-distilled-squad'),\n","        'gpt-neo': (GPT2Tokenizer, GPTNeoForCausalLM, 'EleutherAI/gpt-neo-1.3B'),\n","        'gemma': (AutoTokenizer, AutoModelForCausalLM, 'google/gemma-2b-it')\n","    }\n","    def __init__(self, llm_type: str, load_online=False, save_model=False):\n","        self.device = self.select_device()\n","        self.tokenizer, self.model = self.load_llm(llm_type, load_online, save_model)\n","        self.model.to(self.device)\n","        logging.basicConfig(level=logging.INFO)\n","        logging.info(f\"Model {llm_type} loaded and moved to {self.device}.\")\n","\n","    def load_llm(self, llm_type: str, load_online: bool, save_model: bool):\n","\n","        tokenizer_class, model_class, model_path = self.model_classes[llm_type]\n","\n","        if not load_online:\n","            model_path = f\"{project_path}/models/{model_path}\"\n","\n","        tokenizer = tokenizer_class.from_pretrained(model_path)\n","        model = model_class.from_pretrained(model_path)\n","\n","        if save_model:\n","            tokenizer.save_pretrained(f'{project_path}/models/{model_path}')\n","            model.save_pretrained(f'{project_path}/models/{model_path}')\n","\n","        return tokenizer, model\n","\n","\n","    @staticmethod\n","    def select_device() -> str:\n","        return 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","    def generate_text(self, input_text: str, context: str = '') -> str:\n","        raise NotImplementedError(\"The generate_text method should be implemented by the subclass.\")\n","\n","    def free_memory(self):\n","        del self.model\n","        del self.tokenizer\n","        gc.collect()\n","        torch.cuda.empty_cache()"],"metadata":{"id":"DRAdIqF3kqJo","executionInfo":{"status":"ok","timestamp":1717841872676,"user_tz":-210,"elapsed":3,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## GPT2"],"metadata":{"id":"mTRHbbc58yIz"}},{"cell_type":"code","source":["class GPT2(LLM):\n","    def __init__(self, load_online=False, save_model=False):\n","        super().__init__('gpt2', load_online, save_model)\n","        self.max_length = 1024\n","\n","    def generate_text(self, input_text: str, context: str = '') -> str:\n","        # Truncate the context if necessary to fit within the 1024 token limit\n","        max_context_length = self.max_length - len(\"Context: \\nQuestion: \\nAnswer:\")\n","        context = context[:max_context_length]\n","\n","        # Construct the prompt with the truncated context\n","        prompt = f\"Context: {context}\\nQuestion: {input_text}\\nAnswer:\"\n","\n","        # Encode the prompt and generate the response\n","        inputs = self.tokenizer.encode(prompt, return_tensors='pt').to(self.device)\n","        outputs = self.model.generate(\n","            inputs,\n","            max_new_tokens=150,\n","            # max_length=80,\n","            temperature=0.7,\n","            top_p=0.9,\n","            top_k=50,\n","            num_return_sequences=1,\n","            pad_token_id=self.tokenizer.eos_token_id,\n","            do_sample=True\n","        )\n","\n","        # Decode the output and extract the response\n","        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n","        response = response.replace(prompt, '').strip()\n","        return response.split('\\n')[0]\n"],"metadata":{"id":"54UnFDdY9Hzl","executionInfo":{"status":"ok","timestamp":1717842341076,"user_tz":-210,"elapsed":366,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":["## t5"],"metadata":{"id":"bTjBZyNpEezi"}},{"cell_type":"code","source":["class T5(LLM):\n","    def __init__(self, load_online=False, save_model=False):\n","        super().__init__('t5', load_online, save_model)\n","        self.max_length = 512\n","\n","    def generate_text(self, input_text: str, context: str = None, truncate_context=True) -> str:\n","        if context and truncate_context:\n","            max_context_length = self.max_length - len(\"question:  context: \")\n","            context = context[:max_context_length]\n","\n","        prompt = f\"question: {input_text} context: {context}\" if context else f\"question: {input_text}\"\n","        input_ids = self.tokenizer.encode(prompt, return_tensors='pt', max_length=self.max_length, truncation=True).to(self.device)\n","        outputs = self.model.generate(input_ids, max_new_tokens=150, num_beams=1, early_stopping=False)\n","        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n","        return response"],"metadata":{"id":"CS6-G5GMEeDe","executionInfo":{"status":"ok","timestamp":1717843352192,"user_tz":-210,"elapsed":376,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":["## BERT"],"metadata":{"id":"kZqUha0OG81c"}},{"cell_type":"code","source":["class BERT(LLM):\n","    def __init__(self, load_online=False, save_model=False):\n","        super().__init__('bert', load_online, save_model)\n","        self.max_length = 512\n","\n","    def generate_text(self, input_text: str, context: str = '', truncate_context=True) -> str:\n","        if context and truncate_context:\n","            max_context_length = self.max_length - len(input_text)\n","            context = context[:max_context_length]\n","\n","        self.model.to(self.device)\n","        nlp = pipeline('question-answering', model=self.model, tokenizer=self.tokenizer, device=0 if self.device == 'cuda' else -1)\n","        result = nlp(question=input_text, context=context)\n","        return result['answer']"],"metadata":{"id":"00dae2leG-LT","executionInfo":{"status":"ok","timestamp":1717841872677,"user_tz":-210,"elapsed":3,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## Distil BERT"],"metadata":{"id":"YBkBRlkZJMPx"}},{"cell_type":"code","source":["class DistilBERT(LLM):\n","    def __init__(self, load_online=False, save_model=False):\n","        super().__init__('distil-bert', load_online, save_model)\n","        self.max_length = 512\n","\n","    def generate_text(self, input_text: str, context: str = '', truncate_context=True) -> str:\n","        if context and truncate_context:\n","            max_context_length = self.max_length - len(input_text)\n","            context = context[:max_context_length]\n","\n","        nlp = pipeline('question-answering', model=self.model, tokenizer=self.tokenizer, device=0 if self.device == 'cuda' else -1)\n","        result = nlp(question=input_text, context=context)\n","        return result['answer']"],"metadata":{"id":"muUrhJFlJOUU","executionInfo":{"status":"ok","timestamp":1717841873057,"user_tz":-210,"elapsed":383,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["## GPT-Neo"],"metadata":{"id":"Cme1-CrhLlJ2"}},{"cell_type":"code","source":["class NeoGPT(LLM):\n","    def __init__(self, load_online=False, save_model=False):\n","        super().__init__('gpt-neo', load_online, save_model)\n","        self.max_length = 1024\n","\n","    def generate_text(self, input_text: str, context: str = None, truncate_context=True) -> str:\n","        if context and truncate_context:\n","            max_context_length = self.max_length - len(\"answer this question:  based on this context: \")\n","            context = context[:max_context_length]\n","\n","        prompt = f\"answer this question: {input_text}\\nbased on this context: {context}\" if context else f\"question: {input_text}\"\n","        inputs = self.tokenizer.encode(prompt, return_tensors='pt').to(self.device)\n","        outputs = self.model.generate(\n","            inputs,\n","            max_new_tokens=150,\n","            # max_length=100,\n","            num_return_sequences=1,\n","            pad_token_id=self.tokenizer.eos_token_id,\n","            num_beams=5,\n","            temperature=0.7,\n","            top_k=50,\n","            top_p=0.95,\n","            no_repeat_ngram_size=2,\n","            do_sample=True\n","        )\n","\n","        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n","        return response"],"metadata":{"id":"OlHq6oDMLnNc","executionInfo":{"status":"ok","timestamp":1717843379245,"user_tz":-210,"elapsed":447,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":["## Gemma"],"metadata":{"id":"yJmD43xgSJrm"}},{"cell_type":"code","source":["class Gemma(LLM):\n","    def __init__(self, load_online=False, save_model=False):\n","        super().__init__('gemma', load_online, save_model)\n","        self.max_length = 512\n","\n","    def generate_text(self, input_text: str, context: str = '', truncate_context=True) -> str:\n","        if context and truncate_context:\n","            max_context_length = self.max_length - len(\"Context:  Question:  Answer:\")\n","            context = context[:max_context_length]\n","\n","        prompt = f\"Context: {context}\\nQuestion: {input_text}\\nAnswer:\"\n","        inputs = self.tokenizer(prompt, return_tensors='pt', max_length=self.max_length, truncation=True)\n","        inputs = {key: value.to(self.device) for key, value in inputs.items()}\n","\n","        outputs = self.model.generate(\n","            **inputs,\n","            max_new_tokens=80,\n","            # max_length=80,\n","            temperature=0.7,\n","            top_p=0.9,\n","            top_k=50,\n","            num_return_sequences=1,\n","            pad_token_id=self.tokenizer.eos_token_id,\n","            do_sample=True\n","        )\n","\n","        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n","        response = response.replace(prompt, '').strip()\n","\n","        return response"],"metadata":{"id":"LCgib4NxRuvv","executionInfo":{"status":"ok","timestamp":1717843394503,"user_tz":-210,"elapsed":349,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":["## test LLM class"],"metadata":{"id":"Myfojpj6wtID"}},{"cell_type":"code","source":["llm = BERT()\n","# llm = Gemma(load_online=True)"],"metadata":{"id":"sBG1ITO4-Dbk","executionInfo":{"status":"ok","timestamp":1717802838951,"user_tz":-210,"elapsed":101916,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":103,"outputs":[]},{"cell_type":"code","source":["# Example usage\n","# question = \"say my name.\"\n","# context = 'my name is walter white.'\n","question = \"What is the capital of Iran?\"\n","context = 'tehran is the capital of iran.'\n","context = \"\"\"Well, Prince, so Genoa and Lucca are now just family estates of the Buonapartes. But I warn you, if you don’t tell me that this means war, if you still try to defend the infamies and horrors perpetrated by that Antichrist—I really believe he is Antichrist—I will have nothing more to do with you and you are no longer my friend, no longer my ‘faithful slave’, as you call yourself! But how do you do? I see I have frightened you—sit down and tell me all the news.\"\n","\n","It was in July, 1805, and the speaker was the well-known Anna Pavlovna Scherer, maid of honour and favourite of the Empress Marya Fedorovna. With these words she greeted Prince Vasili Kuragin, a man of high rank and importance, who was the first to arrive at her reception. Anna Pavlovna had had a cough for some days. She was, as she said, suffering from la grippe; grippe being then a new word in St. Petersburg, used only by the elite.\n","\n","All her invitations without exception, written in French, and delivered by a scarlet-liveried footman that morning, ran as follows:\n","\n","\"If you have nothing better to do, Count [or Prince], and if the prospect of spending an evening with a poor invalid is not too terrible, I shall be very charmed to see you tonight between 7 and 10—Annette Scherer.\"\n","\n","\"Heavens! what a virulent attack!\" replied the prince, not in the least disconcerted by this reception. He had just entered, wearing an embroidered court uniform, knee breeches, and shoes, and had stars on his breast and a serene expression on his flat face. He spoke in that refined French in which our grandfathers not only spoke but thought, and with the gentle, patronizing intonation natural to a man of importance who had grown old in society and at court. He went up to Anna Pavlovna, kissed her hand, presenting to her his bald, scented, and shining head, and complacently seated himself on the sofa.\n","\n","\"First of all, dear friend, tell me how you are. Set your friend’s mind at rest,\" said he without altering his tone, beneath the politeness and affected sympathy of which indifference and even irony could be discerned.\n","\n","\"Can one be well while suffering morally? Can one be calm in times like these if one has any feeling?\" said Anna Pavlovna. \"You are staying the whole evening, I hope?\"\n","\n","\"And the fete at the English ambassador’s? Today is Wednesday. I must put in an appearance there,\" said the prince. \"My daughter is coming for me to take me there.\"\n","\n","\"I thought today’s fete had been cancelled. I confess all these festivities and fireworks are becoming wearisome.\"\n","\n","\"If they had known that you wished it, the entertainment would have been put off,\" said the prince, who, like a wound-up clock, by force of habit said things he did not even wish to be believed.\n","\n","\"Don’t tease! Well, and what has been decided about Novosiltsev’s dispatch? You know everything.\"\n","\n","\"What can one say about it?\" replied the prince in a cold, listless tone. \"What has been decided? They have decided that Buonaparte has burnt his boats, and I believe that we are ready to burn ours.\"\n","\n","Prince Vasili always spoke languidly, like an actor repeating a stale part. Anna Pavlovna Scherer on the contrary, despite her forty years, overflowed with animation and impulsiveness. To be an enthusiast had become her social vocation and, sometimes even when she did not feel like it, she became enthusiastic in order not to disappoint the expectations of those who knew her. The subdued smile which, though it did not suit her faded features, always played round her lips expressed, as in a spoiled child, a continual consciousness of her charming defect, which she neither wished, nor could, nor considered it necessary, to correct.\n","\n","In the midst of a conversation on political matters Anna Pavlovna burst out:\n","\n","\"The Empress is pregnant again. Bonaparte will leave all Europe without monarchs. He evidently has conceived that the French are to be an exclusive people. Perhaps he has met his former wife and repented of his sins. To-day no one would be surprised at any change in his plans.\"\n","\n","\"Bonaparte seems to have forgotten that there are laws of political economy. Princes should always remember this. Here is a curious fact. When I was in London there were two women of rank, both of whom I knew personally, who gave birth to sons at precisely the same time. One was at the age of forty, the other at thirty. The first son was delicate, small, and weak; the second was a veritable Hercules. It was all the difference of ten years. Now if you please, the same thing holds true of Europe. Bonaparte forgets that the sovereigns who rule Europe are men like other men. And I dare say if you examined the matter, you would find that the nations that are ruled by these sovereigns are just as susceptible to diseases, to shocks, to all the influences that weaken and ruin men. And I am convinced that Bonaparte, the genius, the man who is so great a personage in his own estimation, is merely an instrument of Providence who is now wreaking vengeance upon the sovereigns of Europe. I can assure you he is no more than that.\"\n","\n","Anna Pavlovna paused in her tirade and looked at Prince Vasili with a questioning smile.\n","\n","\"Well, what do you think?\" she asked, seeing that he had not stirred a muscle. \"Is there anything in what I say?\"\"\"\n","\n","# Anna Pavlovna Scherer was maid of honour and favourite of the Empress Marya Fedorovna. She was suffering from la grippe, a new word in St. Petersburg, used only by the elite. Prince Vasili Kuragin was a man of high rank and importance.\n","# context = 'tehran is the capital of iran.'\n","\n","response = llm.generate_text(question, context)\n","print(\"response:\", response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-yTtMcNRODtk","executionInfo":{"status":"ok","timestamp":1717802845173,"user_tz":-210,"elapsed":6231,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"e4dba630-7bfb-493e-b348-6c415f9e2533"},"execution_count":104,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"output_type":"stream","name":"stdout","text":["response: you—sit down and tell me all the news.\"\n"]}]},{"cell_type":"markdown","source":["## free up memmory"],"metadata":{"id":"G12Zw0BtMu7o"}},{"cell_type":"code","source":["gc.collect()\n","torch.cuda.empty_cache()"],"metadata":{"id":"f2O7gPxqMn86","executionInfo":{"status":"ok","timestamp":1717843427231,"user_tz":-210,"elapsed":647,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["llm.free_memory()"],"metadata":{"id":"Sm2Ch5NdvjRc","executionInfo":{"status":"ok","timestamp":1717843427777,"user_tz":-210,"elapsed":549,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":["# Collection"],"metadata":{"id":"LdexZkZ662Dt"}},{"cell_type":"code","source":["class Collection:\n","    def __init__(self, collection_name: str, transformer_type: str = 'all-MiniLM-L6-v2', load_online=False, save_transformer=False):\n","        self.client = Client(Settings())\n","        existing_collections = [col.name for col in self.client.list_collections()]\n","        if collection_name in existing_collections:\n","            self.client.delete_collection(collection_name)\n","        self.collection = self.client.get_or_create_collection(collection_name)\n","        self.vectorizer = self.load_sentence_transformer(transformer_type, load_online, save_transformer)\n","\n","    def load_sentence_transformer(self, transformer_type: str, load_online: bool, save_transformer: bool):\n","        transformer_path = f'{project_path}/models/{transformer_type}' if not load_online else transformer_type\n","        vectorizer = SentenceTransformer(transformer_path)\n","\n","        if save_transformer:\n","            vectorizer.save(f'{project_path}/models/{transformer_type}')\n","\n","        return vectorizer\n","\n","    def add_contexts(self, context_data: list):\n","        vectors = self.vectorizer.encode(context_data)\n","        ids = [f\"context_{i}\" for i in range(len(context_data))]\n","        self.collection.add(ids=ids, embeddings=vectors.tolist(), documents=context_data)\n","        print(\"Documents added to ChromaDB.\")\n","\n","    def retrieve_contexts(self, question: str, top_n: int = 1):\n","        question_vector = self.vectorizer.encode([question])[0].tolist()\n","        results = self.collection.query(query_embeddings=[question_vector], n_results=top_n)\n","        results = results['documents'][0]\n","        return results[:top_n]"],"metadata":{"id":"AQIdviiA6i4H","executionInfo":{"status":"ok","timestamp":1717841873057,"user_tz":-210,"elapsed":3,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["## test Collection class"],"metadata":{"id":"ovlSNOQQwwPb"}},{"cell_type":"code","source":["# tranformer types:\n","\n","# default => all-MiniLM-L6-v2\n","# paraphrase-MiniLM-L6-v2\n","# paraphrase-xlm-r-multilingual-v1\n","# stsb-roberta-large"],"metadata":{"id":"DM5CKh11UQJ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["collection = Collection('rag')\n","\n","context_data = [\n","    \"The capital of France is Paris. It is known for its art, culture, and cuisine.\",\n","    \"The Great Wall of China is one of the greatest wonders of the world.\",\n","    \"The Amazon rainforest is a moist broadleaf forest that covers most of the Amazon basin of South America.\",\n","    \"The Amazon rainforest is a moist broadleaf forest that covers most of the Amazon basin of South Asia.\"\n","]\n","collection.add_contexts(context_data)"],"metadata":{"id":"FzCnp-Znw47j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response = collection.retrieve_contexts('amazon', top_n=2)\n","\n","print(response)"],"metadata":{"id":"OYQlpAekWYzB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# RAG"],"metadata":{"id":"c-HzDeeB69UN"}},{"cell_type":"code","source":["class RAG:\n","    def __init__(self, llm: LLM, collection: Collection):\n","        self.llm = llm\n","        self.collection = collection\n","\n","    def generate_response(self, query: str, top_n: int=1) -> str:\n","        retrieved_contexts = self.collection.retrieve_contexts(query, top_n)\n","        print(retrieved_contexts)\n","        retrieved_contexts = '\\n'.join(retrieved_contexts)\n","        response = self.llm.generate_text(query, retrieved_contexts)\n","        return response\n"],"metadata":{"id":"pRN9IYwTHNAN","executionInfo":{"status":"ok","timestamp":1717842245723,"user_tz":-210,"elapsed":363,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["## test RAG class"],"metadata":{"id":"sNCKr-Kaw0NY"}},{"cell_type":"code","source":["llm = GPT2()\n","collection = Collection('rag')\n","\n","context_data = [\n","    \"The capital of France is Paris. It is known for its art, culture, and cuisine.\",\n","    \"The Great Wall of China is one of the greatest wonders of the world.\",\n","    \"The Amazon rainforest is a moist broadleaf forest that covers most of the Amazon basin of South America.\",\n","    \"The Amazon rainforest is a moist broadleaf forest that covers most of the Amazon basin of South Asia.\"\n","]\n","collection.add_contexts(context_data)"],"metadata":{"id":"jYTZaTUOHOc8","executionInfo":{"status":"ok","timestamp":1717802968370,"user_tz":-210,"elapsed":13442,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d87dee0d-6a07-4c58-ac46-989af5534df6"},"execution_count":109,"outputs":[{"output_type":"stream","name":"stdout","text":["Documents added to ChromaDB.\n"]}]},{"cell_type":"code","source":["rag = RAG(llm, collection)"],"metadata":{"id":"2VmxmObZHpeb","executionInfo":{"status":"ok","timestamp":1717802968371,"user_tz":-210,"elapsed":12,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":110,"outputs":[]},{"cell_type":"code","source":["query = \"tell me about china?\"\n","response = rag.generate_response(query, top_n=3)\n","print(response)"],"metadata":{"id":"EqIbl7bPbXrh","executionInfo":{"status":"ok","timestamp":1717802975299,"user_tz":-210,"elapsed":6939,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"49de2377-a0a9-42d9-f374-75771e38ba1e"},"execution_count":111,"outputs":[{"output_type":"stream","name":"stdout","text":["It is the largest of the three major tropical regions.\n"]}]},{"cell_type":"markdown","source":["# Summarizer"],"metadata":{"id":"jQwuKM0jFmLz"}},{"cell_type":"code","source":["class Summarizer:\n","\n","    summarizer_models = {\n","        't5': (T5Tokenizer, T5ForConditionalGeneration, 't5-large'),\n","        'bart': (BartTokenizer, BartForConditionalGeneration, 'facebook/bart-large-cnn'),\n","        'pegasus': (PegasusTokenizer, PegasusForConditionalGeneration, 'google/pegasus-large'),\n","    }\n","\n","    def __init__(self, summarizer_model:str='t5', load_online=False, save_model=False):\n","        self.device = self.select_device()\n","        self.tokenizer, self.model = self.load_summarizer(summarizer_model, load_online, save_model)\n","        self.model.to(self.device)\n","        logging.basicConfig(level=logging.INFO)\n","        logging.info(f\"Model {summarizer_model} loaded and moved to {self.device}.\")\n","\n","    def load_summarizer(self, summarizer_model: str, load_online: bool, save_model: bool):\n","\n","        tokenizer_class, model_class, model_path = self.summarizer_models[summarizer_model]\n","\n","        if not load_online:\n","            model_path = f\"{project_path}/models/{model_path}\"\n","\n","        tokenizer = tokenizer_class.from_pretrained(model_path)\n","        model = model_class.from_pretrained(model_path)\n","\n","        if save_model:\n","            tokenizer.save_pretrained(f'{project_path}/models/{model_path}')\n","            model.save_pretrained(f'{project_path}/models/{model_path}')\n","\n","        return tokenizer, model\n","\n","    @staticmethod\n","    def select_device() -> str:\n","        return 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","    def summarize_text(self, input_text: str, context: str = '') -> str:\n","        raise NotImplementedError(\"The generate_text method should be implemented by the subclass.\")\n","\n","    def free_memory(self):\n","        del self.model\n","        del self.tokenizer\n","        gc.collect()\n","        torch.cuda.empty_cache()"],"metadata":{"id":"kUAjaPRIF2b7","executionInfo":{"status":"ok","timestamp":1717800646147,"user_tz":-210,"elapsed":380,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["class T5_Summarizer(Summarizer):\n","    def __init__(self, load_online=False, save_model=False):\n","        super().__init__('t5', load_online, save_model)\n","\n","    def summarize_text(self, input_text: str) -> str:\n","        # model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n","        # tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n","        inputs = self.tokenizer(input_text, return_tensors='pt', max_length=1024, truncation=True)\n","        max_length = min(len(input_text.split()), 150)  # Adjust max length based on input length\n","        min_length = min(len(input_text.split()) // 5, 40)  # Adjust min length based on input length\n","        summary_ids = self.model.generate(inputs['input_ids'], max_length=max_length, min_length=min_length, length_penalty=2.0, num_beams=4, early_stopping=True)\n","        summary = self.tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","        return summary"],"metadata":{"id":"lUE9RMZR2Jq_","executionInfo":{"status":"ok","timestamp":1717800722560,"user_tz":-210,"elapsed":2,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["from transformers import BartForConditionalGeneration, BartTokenizer\n","\n","def summarize_with_bart(text: str) -> str:\n","    model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n","    tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n","    inputs = tokenizer(text, return_tensors='pt', max_length=1024, truncation=True)\n","    max_length = min(len(text.split()), 150)  # Adjust max length based on input length\n","    min_length = min(len(text.split()) // 5, 40)  # Adjust min length based on input length\n","    summary_ids = model.generate(inputs['input_ids'], max_length=max_length, min_length=min_length, length_penalty=2.0, num_beams=4, early_stopping=True)\n","    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","    return summary"],"metadata":{"id":"ZLE0LxmyHuWO","executionInfo":{"status":"ok","timestamp":1717797144399,"user_tz":-210,"elapsed":13894,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["from transformers import T5ForConditionalGeneration, T5Tokenizer\n","\n","def summarize_with_t5(text: str) -> str:\n","    model = T5ForConditionalGeneration.from_pretrained('t5-large')\n","    tokenizer = T5Tokenizer.from_pretrained('t5-large')\n","    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors='pt', max_length=1024, truncation=True)\n","    max_length = min(len(text.split()), 150)  # Adjust max length based on input length\n","    min_length = min(len(text.split()) // 5, 40)  # Adjust min length based on input length\n","    summary_ids = model.generate(inputs, max_length=max_length, min_length=min_length, length_penalty=2.0, num_beams=4, early_stopping=True)\n","    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","    return summary\n","\n"],"metadata":{"id":"lBAvur5NHvq7","executionInfo":{"status":"ok","timestamp":1717797589762,"user_tz":-210,"elapsed":382,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n","\n","def summarize_with_pegasus(text: str) -> str:\n","    model = PegasusForConditionalGeneration.from_pretrained('google/pegasus-large')\n","    tokenizer = PegasusTokenizer.from_pretrained('google/pegasus-large')\n","    inputs = tokenizer(text, return_tensors='pt', max_length=1024, truncation=True)\n","    max_length = min(len(text.split()), 150)  # Adjust max length based on input length\n","    min_length = min(len(text.split()) // 5, 40)  # Adjust min length based on input length\n","    summary_ids = model.generate(inputs['input_ids'], max_length=max_length, min_length=min_length, length_penalty=2.0, num_beams=4, early_stopping=True)\n","    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","    return summary\n"],"metadata":{"id":"HdDnYkaFHx4C","executionInfo":{"status":"ok","timestamp":1717798080521,"user_tz":-210,"elapsed":387,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["context = \"\"\"Well, Prince, so Genoa and Lucca are now just family estates of the Buonapartes. But I warn you, if you don’t tell me that this means war, if you still try to defend the infamies and horrors perpetrated by that Antichrist—I really believe he is Antichrist—I will have nothing more to do with you and you are no longer my friend, no longer my ‘faithful slave’, as you call yourself! But how do you do? I see I have frightened you—sit down and tell me all the news.\"\n","\n","It was in July, 1805, and the speaker was the well-known Anna Pavlovna Scherer, maid of honour and favourite of the Empress Marya Fedorovna. With these words she greeted Prince Vasili Kuragin, a man of high rank and importance, who was the first to arrive at her reception. Anna Pavlovna had had a cough for some days. She was, as she said, suffering from la grippe; grippe being then a new word in St. Petersburg, used only by the elite.\n","\n","All her invitations without exception, written in French, and delivered by a scarlet-liveried footman that morning, ran as follows:\n","\n","\"If you have nothing better to do, Count [or Prince], and if the prospect of spending an evening with a poor invalid is not too terrible, I shall be very charmed to see you tonight between 7 and 10—Annette Scherer.\"\n","\n","\"Heavens! what a virulent attack!\" replied the prince, not in the least disconcerted by this reception. He had just entered, wearing an embroidered court uniform, knee breeches, and shoes, and had stars on his breast and a serene expression on his flat face. He spoke in that refined French in which our grandfathers not only spoke but thought, and with the gentle, patronizing intonation natural to a man of importance who had grown old in society and at court. He went up to Anna Pavlovna, kissed her hand, presenting to her his bald, scented, and shining head, and complacently seated himself on the sofa.\n","\n","\"First of all, dear friend, tell me how you are. Set your friend’s mind at rest,\" said he without altering his tone, beneath the politeness and affected sympathy of which indifference and even irony could be discerned.\n","\n","\"Can one be well while suffering morally? Can one be calm in times like these if one has any feeling?\" said Anna Pavlovna. \"You are staying the whole evening, I hope?\"\n","\n","\"And the fete at the English ambassador’s? Today is Wednesday. I must put in an appearance there,\" said the prince. \"My daughter is coming for me to take me there.\"\n","\n","\"I thought today’s fete had been cancelled. I confess all these festivities and fireworks are becoming wearisome.\"\n","\n","\"If they had known that you wished it, the entertainment would have been put off,\" said the prince, who, like a wound-up clock, by force of habit said things he did not even wish to be believed.\n","\n","\"Don’t tease! Well, and what has been decided about Novosiltsev’s dispatch? You know everything.\"\n","\n","\"What can one say about it?\" replied the prince in a cold, listless tone. \"What has been decided? They have decided that Buonaparte has burnt his boats, and I believe that we are ready to burn ours.\"\n","\n","Prince Vasili always spoke languidly, like an actor repeating a stale part. Anna Pavlovna Scherer on the contrary, despite her forty years, overflowed with animation and impulsiveness. To be an enthusiast had become her social vocation and, sometimes even when she did not feel like it, she became enthusiastic in order not to disappoint the expectations of those who knew her. The subdued smile which, though it did not suit her faded features, always played round her lips expressed, as in a spoiled child, a continual consciousness of her charming defect, which she neither wished, nor could, nor considered it necessary, to correct.\n","\n","In the midst of a conversation on political matters Anna Pavlovna burst out:\n","\n","\"The Empress is pregnant again. Bonaparte will leave all Europe without monarchs. He evidently has conceived that the French are to be an exclusive people. Perhaps he has met his former wife and repented of his sins. To-day no one would be surprised at any change in his plans.\"\n","\n","\"Bonaparte seems to have forgotten that there are laws of political economy. Princes should always remember this. Here is a curious fact. When I was in London there were two women of rank, both of whom I knew personally, who gave birth to sons at precisely the same time. One was at the age of forty, the other at thirty. The first son was delicate, small, and weak; the second was a veritable Hercules. It was all the difference of ten years. Now if you please, the same thing holds true of Europe. Bonaparte forgets that the sovereigns who rule Europe are men like other men. And I dare say if you examined the matter, you would find that the nations that are ruled by these sovereigns are just as susceptible to diseases, to shocks, to all the influences that weaken and ruin men. And I am convinced that Bonaparte, the genius, the man who is so great a personage in his own estimation, is merely an instrument of Providence who is now wreaking vengeance upon the sovereigns of Europe. I can assure you he is no more than that.\"\n","\n","Anna Pavlovna paused in her tirade and looked at Prince Vasili with a questioning smile.\n","\n","\"Well, what do you think?\" she asked, seeing that he had not stirred a muscle. \"Is there anything in what I say?\"\"\"\n","\n","summarizer = T5_Summarizer(load_online=True)\n","summary = summarizer.summarize_text(context)\n","print(summary)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mx1GETenIlr_","executionInfo":{"status":"ok","timestamp":1717801014948,"user_tz":-210,"elapsed":101112,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"8a6d92e4-0547-4419-98d4-fbf7a18af536"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"stream","name":"stdout","text":[": \"The Empress is pregnant again. Bonaparte will leave all Europe without monarchs. Perhaps he has met his former wife and repented.\" \"The Empress is pregnant again.\" \"The Empress is pregnant again.\" \"The Empress is pregnant again.\" \"The Empress is pregnant again.\" \"The Empress is pregnant again.\" \"The Empress is pregnant\n"]}]},{"cell_type":"markdown","source":["# PDF"],"metadata":{"id":"0ylfgAmLrWjQ"}},{"cell_type":"code","source":["def extract_text_from_pdf(pdf_path):\n","    doc = fitz.open(pdf_path)\n","    text = \"\"\n","    for page_num in range(len(doc)):\n","        page = doc.load_page(page_num)\n","        text += page.get_text(\"text\")\n","    return text\n"],"metadata":{"id":"21pFJVfPrcFH","executionInfo":{"status":"ok","timestamp":1717841873058,"user_tz":-210,"elapsed":4,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def preprocess_text(text, chunk_size=500):\n","    text = text.replace('\\n', ' ')  # Replace newlines with spaces\n","    sentences = text.split('. ')  # Split into sentences\n","    chunks = []\n","    chunk = []\n","    length = 0\n","\n","    for sentence in sentences:\n","        chunk.append(sentence)\n","        length += len(sentence.split())\n","\n","        if length > chunk_size:\n","            chunks.append(' '.join(chunk))\n","            chunk = []\n","            length = 0\n","\n","    if chunk:\n","        chunks.append(' '.join(chunk))\n","\n","    return chunks\n"],"metadata":{"id":"78axRor7rfev","executionInfo":{"status":"ok","timestamp":1717841873058,"user_tz":-210,"elapsed":4,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["## Test PDF questioning"],"metadata":{"id":"2CfeU8GzaKdq"}},{"cell_type":"code","source":["pdf_path = f\"{project_path}/tests/micro led 1.pdf\"\n","text = extract_text_from_pdf(pdf_path)\n","contexts = preprocess_text(text)"],"metadata":{"id":"4Q6xtFE3rgOI","executionInfo":{"status":"ok","timestamp":1717841876760,"user_tz":-210,"elapsed":3706,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["collection = Collection('rag')\n","collection.add_contexts(contexts)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wXAVjf3mud5I","executionInfo":{"status":"ok","timestamp":1717841906818,"user_tz":-210,"elapsed":30060,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"18b45a40-0feb-4b06-8d63-0955ed4ac671"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Documents added to ChromaDB.\n"]}]},{"cell_type":"code","source":["# llm = NeoGPT(load_online=True)\n","# llm = BERT()\n","llm = GPT2()\n","# llm = T5()"],"metadata":{"id":"f5zc3ii4ufPI","executionInfo":{"status":"ok","timestamp":1717843436049,"user_tz":-210,"elapsed":4038,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":62,"outputs":[]},{"cell_type":"code","source":["rag = RAG(llm, collection)"],"metadata":{"id":"x7TmnoW0uqeJ","executionInfo":{"status":"ok","timestamp":1717843436050,"user_tz":-210,"elapsed":13,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["question = 'what is One of the most widely anticipated applications of microLEDs?'\n","real_context = \"One of the most widely anticipated applications of microLEDs and RGB capability is in next-generation self-emissive display technol-ogy.10,11\"\n","# gpt2 answer: The main focus of the present study is the application of microLEDs to the use of optical microscopy (OMS), a technique used to detect and detect optical phenomena. In this work, we aim to show that microLEDs can be used as a primary imaging sensor in a number of optical microscopy applications.\n","# T5 answer: optical structures\n","# bert answer: structured illumination microscopy,\n","\n","# question = 'what we should expect from adoption of microled displays?'\n","# real_context = \"The adoption of microLEDs in display devices is expected to enable much brighter, broader color gamut, longer lifetime, and extremely high pixels per inch (PPI) displays.\"\n","\n","response = rag.generate_response(question, 6)\n","\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Owx0UKj0uwMX","executionInfo":{"status":"ok","timestamp":1717843449159,"user_tz":-210,"elapsed":13122,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"ab4e30d1-d5dc-4498-d45a-cc121cf330b7"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["['Deﬁnitions of the key metrics from a non-display application point of view are presented We also highlight optical structures such as photonic crystals, microlens, quantum dots, FIG 1 A schematic diagram illustrating the correlation of key non-display applications (structured illumination microscopy, optogenetic stimulation, multi-contrast imaging, visi- ble light communication, maskless lithography, solid-state lighting) and relevant properties of microLED/LED (external quantum efﬁciency, angle of extraction, modulation band- width, light output power, emission wavelength) It also highlights the electro-optical structures and techniques, such as patterned sapphire substrates, photonic crystals, microlenses, quantum dots, etc., required to modify the key properties Applied Physics Reviews REVIEW scitation.org/journal/are Appl Phys Rev 10, 021306 (2023); doi: 10.1063/5.0125103 10, 021306-2 Published under an exclusive license by AIP Publishing  07 June 2024 12:27:45 phosphors, etc., that are needed to modify the electro-optical proper- ties of the microLEDs Finally, the outlook and challenges associated with the integration of advanced structures with microLEDs and their broader applications are discussed The schematic diagram encom- passing the review is shown in Fig 1 II NON-DISPLAY APPLICATION AREAS MicroLEDs have been extensively explored as pixels for next- generation displays with ultra-high brightness, deeper color gamut, and longer lifetime.28–31 The high luminance, energy efﬁciency, reli- ability, low cost, and bio-compatibility of microLEDs also enable them to be used in various non-display technologies such as visible light communications (VLC), photolithography, optogenetics stimulation, light sources for structured illumination microscopy (SIM), and super- resolution imaging.22,25–27,32,33 This section focuses on the system setup and recent progress of each of these applications A Visible Light Communication (VLC) The usage of microLEDs in visible light communication (VLC) systems has been investigated both as emitter devices and as photode- tectors (PD).19–21,34 The VLC system, shown in Fig 2(c), consists of three primary components: an optical transmitter, an optical channel, and a receiver.35 The optical transmitter contains the waveform gener- ator, encoders, driver electronics, microLED emitters, and transmitter optics The optical channel allows for data transfer through air or another desired medium The receiver contains receiver optics, photo- detectors, ampliﬁers, and decoders The schematic diagram of a mea- surement setup for frequency response characterization having similar components is also shown in Fig 2(a) The lower RC values of microLEDs arising from their small size (1–100 lm) and short carrier lifetime result in a high modulation bandwidth A higher 3-dB modulation bandwidth allows a higher data rate transfer in the communication system These characteristics make microLEDs an attractive choice for optical data emitters in high-speed FIG 2 The schematic diagram of a visible light communication (VLC) system (a) The system setup to measure the frequency response of microLEDs The system consists of a vector network analyzer, a bias-tee for operating the microLED, a plastic ﬁber for coupling the light, and a photodetector (b) A plot showing improved frequency response with increasing injected current density The current is increased from 5 to 40 mA A maximum 3-dB modulation bandwidth of 756 MHz is shown in the inset at 2000 A/cm2 (c) The system setup for VLC communication data-rate characterization consists of the signal quality analyzer, 20 dB ampliﬁer, bias-tee, photodetector, and a digital oscilloscope', 'This changes the lattice constant of InGaN crystal from approximately 3.18 \\x05 3.55 A ˚ Reproduced with permission from Freitas et al., AIP Adv 6, 085308 (2016) Copyright 2016, Authors, licensed under a Creative Commons Attribution (CC BY) License.239 Applied Physics Reviews REVIEW scitation.org/journal/are Appl Phys Rev 10, 021306 (2023); doi: 10.1063/5.0125103 10, 021306-15 Published under an exclusive license by AIP Publishing  07 June 2024 12:27:45 microLEDs is still notably low because increasing indium (In) content in the alloy degrades crystal quality due to a large lattice mismatch and low-temperature growth.249 Various fabrication techniques, such as strain engineering, lower growth rates, and high growth temperatures, are required to tackle the low EQE problem facing III-nitride based red microLEDs.250 A more detailed review of the development of red microLEDs can be found in the manuscript from Iida et al.250 Apart from applications in display technologies, the development of different colored efﬁcient microLEDs is important for other applica- tions such as optogenetics The activation or suppression of different cells expressed by different proteins is highly desirable for more precise control over the neuronal activity Red-and-blue-colored microLED-based optoelectronic probes have been used to demonstrate bi-directional neuronal activity manipulation.251,252 Dual-colored microLED arrays have also been used as VLC transmitters and dem- onstrated error-free data rates of 1.79–3.35 Gbps in a dual-wavelength multiplexing scheme.253 Further work is needed to enhance the efﬁ- ciency of longer wavelength microLEDs as longer wavelengths enable deeper neural cell stimulation in optogenetics and wavelength division multiplexing in VLC systems.254,255 V OUTLOOK AND CHALLENGES As discussed in the article, MicroLED/LED technology has been incorporated into a range of applications beyond display applications MicroLEDs based on InGaN/GaN have consistently higher efﬁciencies than competing approaches even as we scale down the device dimen- sions to sub-micron size for blue, green, and red emissions The efﬁ- ciency of the red-colored InGaN/GaN microLEDs can stand further improvement, especially at smaller dimensions The ability to achieve RGB emission from a single material stack will open a wide array of applications with increasingly complex system integration Additionally, the relatively high cost of GaN epi wafers remains a chal- lenge to be addressed, as microLED technology is adopted into a greater number of applications such as point-of-care medical applica- tions like phototherapy and skin treatments.256,257 The adoption of microLEDs in visible light communication (VLC) systems has rapidly grown with improved data transfer rates An increase in the modulation bandwidth is the driving factor for the higher data transfer rates Device miniaturization and the decrease in carrier lifetime of microLEDs can further improve this trend Additionally, VLC systems that use an array of microLEDs as emitters have the potential to enhance the data transfer rates even higher, albeit with the increased system complexity Implementation of VLC in lab- oratory setup is routinely demonstrated, but the real-life system still remains a challenge Many critical issues such as reliability, scalability, and compactness related to the commercialization of the VLC systems remain to be addressed As optogenetics advances our understanding of neural circuits, microLEDs will have an increasingly prevalent role in delivering spa- tially resolved single-neuron stimulation', 'OPTICAL STRUCTURES FOR IMPROVED PERFORMANCE Despite the superior performance of microLEDs when compared with OLEDs, modiﬁcation in the key properties of microLEDs is often required for non-display applications Electro-optical components such as photonic crystals, nanostructures, microlenses, Fresnel lenses, quantum dots, phosphors, etc., are integrated with the traditional microLEDs to improve the output performance Key optical compo- nents that can enhance the performance metrics of microLEDs and make them more suitable for use in non-display applications are dis- cussed in Secs IVA–V A Extraction efficiency enhancement The low extraction efﬁciency of microLEDs originates from the traditionally grown epilayer structure of the GaN LEDs.6,106,144 A typi- cal GaN epi structure is grown hetero-epitaxially on a sapphire sub- strate due to the lack of availability of a suitable substrate for homoepitaxial growth.145,146 The photons generated inside the GaN FIG 9 A graph showing the 3-dB modulation bandwidth of microLEDs as a func- tion of current density for different pixel sizes ranging from 60 to 160 lm The mod- ulation bandwidth initially increases as the current density of microLED increases and then saturates for higher current density operation The smaller pixel sizes achieve higher modulation bandwidth as they can be operated at higher current density The markers on the plot denote the maximal modulation bandwidth in the measurement for each size Reproduced with permission from Huang et al., Phys Status Solidi A 215, 1800484 (2018).122 Copyright 2018 WILEY-VCH Verlag GmbH & Co KGaA, Weinheim Applied Physics Reviews REVIEW scitation.org/journal/are Appl Phys Rev 10, 021306 (2023); doi: 10.1063/5.0125103 10, 021306-9 Published under an exclusive license by AIP Publishing  07 June 2024 12:27:45 layer with high refractive index (n \\x04 2.4) undergo total internal reﬂec- tion (TIR) at the GaN-air interface This consequently reduces the overall efﬁciency of the extracted light.147 Researchers have suggested methods including chip shaping, photonic crystals, surface roughness, and mesa shape modiﬁcation to improve the extraction efﬁciency of microLEDs.148–152 This section discusses the techniques for extraction efﬁciency enhancement in the context of various non-display applications 1 Photonic crystals Photonic crystals (PhCs) are repeated dielectric structures of length scales similar to the wavelength of light.148,153,154 These crystals have the capability to modify spontaneous light emission by creating a photonic bandgap that can interact with the electronic bandgap of the emission material.155 The photonic bandgap can be utilized in two ways to increase the extraction efﬁciency: inhibiting the emission of the guided modes or redirecting trapped light into radiated modes The photonic crystals should be physically very close to the active light emitting region to maximize their impact Wierer et al demonstrated electrically operated InGaN/GaN LEDs with photonic crystals having a tunnel junction to provide lateral current spreading to the photonics crystals.154 This work reports increased microLED radiance and an approximately 1.5x total increase in light extraction with photonic crystals incorporation Additionally, the far-ﬁeld radiation pattern of LEDs with PhC was also radically different than planar LEDs.154 Oder et al demonstrated extraction efﬁciency enhancement of 63% in InGaN/GaN blue (460 nm) microLEDs and 95% in AlInGaN/ GaN UV (340 nm) microLEDs', 'further advanced the tech- nique by combining a CMOS-controlled microLED array with a projection system and translation stage to achieve written features as small as 8 lm.27 Building further on the same setup, Guilhabert et al reported mask-fee direct pattern writing with features as small as 500 nm by primarily modifying the projection optics.96 They also showed the fabrication of InGaN micro-LEDs using the same setup Recently, Wu et al reported a UV micro-LED display with full high- deﬁnition of 960 \\x02 540 and 1920 \\x02 1080 for pattern-programmable maskless photolithography on resist-coated wafers.98 Figure 6(b) shows the microLED display and a patterned Si substrate using mask- less lithography All these reports show the potential of microLED technology for photolithography applications that require minimal setup and provide a budget-friendly alternative to traditional laser- based systems III PERFORMANCE METRICS FOR NON-DISPLAY APPLICATIONS The various applications discussed in Sec II have different pri- mary enabling performance properties Table I summarizes the reviewed non-display applications and the key desirable properties MicroLED technology offers superior performance than organic light emitting diodes (OLEDs) for key properties such as brightness, response time, and lifetime Table II summarizes the performance comparison between the microLEDs and OLED technology.99 Many of the metrics, such as superior brightness, reliability, and lifetime, make microLEDs well-suited to both display and non-display, but some of the key performance metrics for non-display applications dif- fer from those for display applications This section discusses the key performance parameters of microLEDs that must be optimized or enhanced for non-display applications These metrics include optical extraction, angle of extraction, modulation bandwidth, light output power, and response time FIG 6 (a) A micro-projection system used for maskless UV photolithography The system consists of CMOS driven microLED array, a horizontally mounted objective for light collection, a 45\\x03 mirror for directing light downward, a vertical objective, and a piezo-driven stage for z-translation for focusing Reproduced with permission from Elfstr€ om et al., Opt Express 17(26), 23522–23529 (2009).27 Copyright 2009 Optical Society of America (b) Mirror pattern of letter “NTHU” programmed on a 1920 \\x02 1080 microLED display and then revealed on a photoresist coated Si wafer using maskless photolithography Reproduced with permission from M.-C Wu and I.-T Chen, Adv Photonics Res 2, 2100064 (2021).98 Copyright 2021 Authors, licensed under a Creative Commons Attribution 4.0 License TABLE I Non-display applications reviewed and enabling primary performance characteristics Application Properties VLC Efﬁciency, modulation BW Optogenetics Size/implantability, Output power SIM Output power, beam shaping Imaging Output power, pattern control Maskless photolithography Intensity, wavelength control TABLE II Performance comparison of key properties between OLED and microLED technology.99 Properties OLED MicroLED Mechanism Self-emissive Self-emissive Brightness 1000 Cd/m2 106 Cd/m2 Lifetime 30 000 h 100 000 h Response time Microsecond Nanosecond Pixel density (PPI) up to 2500 up to 30 000 Energy Medium Low Cost Low High Applied Physics Reviews REVIEW scitation.org/journal/are Appl Phys Rev 10, 021306 (2023); doi: 10.1063/5.0125103 10, 021306-7 Published under an exclusive license by AIP Publishing  07 June 2024 12:27:45 A Optical extraction efficiency—EQE vs IQE Blue microLEDs have internal quantum efﬁciencies (IQEs) that can exceed ninety percent as a result of advances in growth techniques that have yielded high-quality materials and crystal structures.100–103 However, the external quantum efﬁciency (EQE) of GaN-based microLEDs, deﬁned as the ratio of the number of photons emitted vs the number of photons internally generated, is comparatively low with a peak EQE of generally smaller than 15%.104–106 The EQE of the microLEDs can be viewed as the product of two separate efﬁciencies: IQE and light extraction efﬁciency (LEE).107 While IQE is signiﬁcantly improved over the years, LEE has been a limiting factor.100,108,109 Low LEE is primarily due to the large refractive index difference between air and semiconductors that traps light from total internal reﬂection (TIR) and Fresnel loss at the interface.110 For example, the external efﬁciency could be as low as 4.3% in a typical semiconductor material with a refractive index of 2.4', 'reported a white light VLC system that used semi-polar blue microLEDs and yellow phosphors to achieve a data rate of 2.805 Gbps.128 The higher data rate and band- width of the system are attributed to the improved radiative efﬁciency of the semi-polar blue microLEDs resulting from the reduced quantum-conﬁned Stark effect (QCSE) A hybrid strategy of mixing small-sized and large-sized phos- phors can improve the non-uniformity of the system to a great extent with only a small reduction in efﬁciency However, this remains a chal- lenge as mesa dimensions shrink to smaller areas of 5 l m and below.204 Recently, GE has developed a sub-micron sized red phos- phor K2SiF6:Mn4þ (KSF) and KSF inks suitable for microLEDs that can be deposited by low-cost methods such as ink-jet printing, slot die coating, or spin coating.233 These recent developments pave the way for phosphors to be further utilized in microLED applications by over- coming challenges due to their size 3 Compound semiconductor layers Electroluminescence, which is responsible for spontaneous light emission upon the passage of electric current, dates back to 1907 when Round discovered it in silicon carbide (SiC) crystals.234 Further under- standing of materials and luminescent phenomena makes tuning of bandgap an obvious choice for the creation of light emitting diodes of different colors.235–238 Red LEDs have traditionally used AlGaInP crystals, but recent focus has shifted to indium gallium nitride (InGaN) crystals as they offer a wide spectral range from ultraviolet to infrared.239 InGaN bandgap energy can be tuned from 0.67 to 3.42 eV by changing the composition of the alloy.129,240,241 Figure 17 shows the energy bandgap of hexagonal gallium nitride (h-GaN) as a func- tion of lattice constant that is controlled by the indium (In) concentra- tion in the alloy The external quantum efﬁciency (EQE) of the microLED decreases with decreasing device size due to the increased non- radiative recombination, also known as efﬁciency droop.100 While the peak EQE of a 20 \\x02 20 lm blue microLED has been reported to be as high as 33%, AlGaInP-based red microLEDs suffer signiﬁcantly from efﬁciency droop due to high surface recombination and long carrier lifetime at smaller dimensions (<50 lm).242–244 They also suffer from poor thermal stability at high temperatures.245,246 This has resulted in a growing interest in creating red microLEDs that are based on III- nitride materials, in particular InGaN.247,248 The EQE of red InGaN FIG 16 Phosphor structure and emission spectrum (a) The crystal structure of a nar- rowband red-emitting phosphor material Sr4[LiAl11N14]:Eu2þ along [001] direction The nitride is the host material responsible for the crystal structure The rare earth metal Eu2þ is the activator material responsible for light emission (b) Excitation (peak at 460nm) and emission spectra of the phosphor Sr4[LiAl11N14]:Eu2þ It shows red lumi- nescence with an emission peak at 670nm and a bandwidth of 85nm Reprinted with permission from Wilhelm et al., Chem Mater 29, 1204 (2017).229 Copyright 2009 American Chemical Society FIG 17 The plot of energy bandgap vs lattice constant for hexagonal III-nitride alloys The energy bandgap of the h-GaN changes from 3.42 to 0.67 eV as the indium content increases in the alloy', '\\ue929 View Online \\ue92d Export Citation REVIEW ARTICLE |  MAY 01 2023 MicroLED/LED electro-optical integration techniques for non-display applications  \\ue901 V Kumar \\ue923   ; I Kymissis \\ue923  Appl Phys Rev 10, 021306 (2023) https://doi.org/10.1063/5.0125103 \\ue918 CHORUS  07 June 2024 12:27:45 MicroLED/LED electro-optical integration techniques for non-display applications Cite as: Appl Phys Rev 10, 021306 (2023); doi: 10.1063/5.0125103 Submitted: 9 September 2022  Accepted: 20 March 2023  Published Online: 1 May 2023 V Kumara) and I Kymissisa) AFFILIATIONS Department of Electrical Engineering, Columbia University, New York, New York 10027, USA a)Author to whom correspondence should be addressed: vk2440@columbia.edu and ik2174@columbia.edu ABSTRACT MicroLEDs offer an extraordinary combination of high luminance, high energy efﬁciency, low cost, and long lifetime These characteristics are highly desirable in various applications, but their usage has, to date, been primarily focused toward next-generation display technologies Applications of microLEDs in other technologies, such as projector systems, computational imaging, communication systems, or neural stim- ulation, have been limited In non-display applications which use microLEDs as light sources, modiﬁcations in key electrical and optical char- acteristics such as external efﬁciency, output beam shape, modulation bandwidth, light output power, and emission wavelengths are often needed for optimum performance A number of advanced fabrication and processing techniques have been used to achieve these electro- optical characteristics in microLEDs In this article, we review the non-display application areas of the microLEDs, the distinct opto- electrical characteristics required for these applications, and techniques that integrate the optical and electrical components on the microLEDs to improve system-level efﬁcacy and performance Published under an exclusive license by AIP Publishing https://doi.org/10.1063/5.0125103 TABLE OF CONTENTS I INTRODUCTION                                  1 II NON-DISPLAY APPLICATION AREAS              3 A Visible Light Communication (VLC)            3 B Optogenetic stimulation                        4 C Structured Illumination Microscopy (SIM)       5 D Other imaging techniques                      5 E Maskless photolithography                     6 III PERFORMANCE METRICS FOR NON-DISPLAY APPLICATIONS                                  7 A Optical extraction efficiency—EQE vs IQE       8 B Angle of extraction                            8 C Modulation bandwidth                        9 D Emission wavelength                          9 E Light Output Power (LOP)                     9 IV OPTICAL STRUCTURES FOR IMPROVED PERFORMANCE                                  9 A Extraction efficiency enhancement              9 1 Photonic crystals                          10 2 Surface roughness                         10 3 Patterned Sapphire Substrate (PSS)          11 B Beam shaping                                11 1 Microlens                                 12 2 TIR Fresnel lens                           12 C Wavelength management techniques            13 1 Colloidal Quantum Dots (QDs)             14 2 Phosphor                                 14 3 Compound semiconductor layers            15 V OUTLOOK AND CHALLENGES                    16 I INTRODUCTION The light emitting diodes (LEDs) based on InGaN/GaN semicon- ductors have become ubiquitous These devices are an integral part of the solid-state lighting ecosystem including automobiles, smartphones, home lighting systems, and industrial lighting.1–5 The adoption of LEDs has enabled additional functionalities in the form of longer life- time, more reliable operation, smaller form factor, and lower power consumption in almost every application Much of the effort toward cost reduction in LEDs has been focused on increasing external efﬁciency using improved material growth techniques and optimizing fabrication processes.6 The reduc- tion in high costs of GaN semiconductor-based light emitting diodes is a challenge that needs to be addressed']\n","MicroLEDs are being used in several applications such as laser photonics, laser-cutters, microfluidic converters, and other applications. They are being used for an ultra-high-power optical system. However, the main focus of this paper is the question of what is the most commonly used applications of microLEDs, and the answer is that microLEDs are not being\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"WwE5_iYbXlqH"},"execution_count":null,"outputs":[]}]}