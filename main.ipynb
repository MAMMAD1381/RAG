{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"mount_file_id":"1xGeaM-oFVeEliD38KtLRTtP4lPrQVkz-","authorship_tag":"ABX9TyOMLO0rCXRYqDottg1/sFLQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"354ffd0f13104621bdfd29d52ed583c6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c46bb9b7bb4641f4b76f04a1c882f656","IPY_MODEL_cdee9e82795b4b76a204cc103bae02f1","IPY_MODEL_1874c3ef2c954362ab51debd01bae886"],"layout":"IPY_MODEL_31a6f3a4f896410bbf23c74563918d56"}},"c46bb9b7bb4641f4b76f04a1c882f656":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e40bd0faef24cb0b9a7ae556a3f5b31","placeholder":"​","style":"IPY_MODEL_901947eeb0f84d379bd33ab7a9e714a5","value":"tokenizer_config.json: 100%"}},"cdee9e82795b4b76a204cc103bae02f1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d9ad60c4a044aca832ced81802df18e","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_869b9c3bd2c94403af32360dc803b6d9","value":26}},"1874c3ef2c954362ab51debd01bae886":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ea934501e804c8caa9200c2614e444e","placeholder":"​","style":"IPY_MODEL_3915cc231e434e9e9f14472a57f5e031","value":" 26.0/26.0 [00:00&lt;00:00, 617B/s]"}},"31a6f3a4f896410bbf23c74563918d56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e40bd0faef24cb0b9a7ae556a3f5b31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"901947eeb0f84d379bd33ab7a9e714a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4d9ad60c4a044aca832ced81802df18e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"869b9c3bd2c94403af32360dc803b6d9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7ea934501e804c8caa9200c2614e444e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3915cc231e434e9e9f14472a57f5e031":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"414b3a31d0b24fd49542ff064dd819e5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_303d11d5228842aba90b2891dff425af","IPY_MODEL_ad3685c1507d460a8b519f02a020293d","IPY_MODEL_1c8f02f95e1f4a359189c7ad17ee96a1"],"layout":"IPY_MODEL_c571d9764d5f48babca37e3ec093826d"}},"303d11d5228842aba90b2891dff425af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a79e48d41fe64295b4f85b58b2d7184d","placeholder":"​","style":"IPY_MODEL_844efac858254dfdb3270f899027705b","value":"vocab.json: 100%"}},"ad3685c1507d460a8b519f02a020293d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4bf152acc144d9493769568e7f50a18","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1ba3af30219845f8b445bcd15a420186","value":1042301}},"1c8f02f95e1f4a359189c7ad17ee96a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa5eed0f38a6457cb655e6b255bc84e8","placeholder":"​","style":"IPY_MODEL_f14e682676c04c348661a560b54a554a","value":" 1.04M/1.04M [00:00&lt;00:00, 6.73MB/s]"}},"c571d9764d5f48babca37e3ec093826d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a79e48d41fe64295b4f85b58b2d7184d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"844efac858254dfdb3270f899027705b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4bf152acc144d9493769568e7f50a18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ba3af30219845f8b445bcd15a420186":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fa5eed0f38a6457cb655e6b255bc84e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f14e682676c04c348661a560b54a554a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6515cd6c73aa4e07bb4762a7fe7eb0b1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f7aa5d52ce60467ea0f410fb58507dab","IPY_MODEL_02835790a73340edb2acbc3f18ac289f","IPY_MODEL_d50b6ea43d8543f1b64dd16bc4a9ee51"],"layout":"IPY_MODEL_1d6e8ec5bc104e50a5e1fe9129104f9f"}},"f7aa5d52ce60467ea0f410fb58507dab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_23b3ac7edeae4762a50821fc76b9b2b3","placeholder":"​","style":"IPY_MODEL_1d6018e6756b43138958199de5380fca","value":"merges.txt: 100%"}},"02835790a73340edb2acbc3f18ac289f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_52b90cb98d81405a8ef0519caec18403","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_94133e9978104669a6c03327e4e6c2e1","value":456318}},"d50b6ea43d8543f1b64dd16bc4a9ee51":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d65493e278a34e8cbd431dd0202b9f34","placeholder":"​","style":"IPY_MODEL_2c9b278a655341478438e2defe9d61b7","value":" 456k/456k [00:00&lt;00:00, 5.02MB/s]"}},"1d6e8ec5bc104e50a5e1fe9129104f9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23b3ac7edeae4762a50821fc76b9b2b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d6018e6756b43138958199de5380fca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"52b90cb98d81405a8ef0519caec18403":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94133e9978104669a6c03327e4e6c2e1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d65493e278a34e8cbd431dd0202b9f34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c9b278a655341478438e2defe9d61b7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"392bab628ad74647a550f360623e5fd3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bf25aead1cb34520bafddaef004f8f40","IPY_MODEL_8b5f2b9969e04f2aa46ac85d1dc4b112","IPY_MODEL_527663a6d56a401da669c4d71c23c68b"],"layout":"IPY_MODEL_157642762f804d43890a7d866fb0d992"}},"bf25aead1cb34520bafddaef004f8f40":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1ede85a601b4f64866afa3aa753fcf6","placeholder":"​","style":"IPY_MODEL_9dc2373d7b34405495ad06239c22c7c1","value":"tokenizer.json: 100%"}},"8b5f2b9969e04f2aa46ac85d1dc4b112":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2d736c27af04a8e9c716fcbd6fe5ea9","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0179de6eb51f4900aae73b9cd593a6c7","value":1355256}},"527663a6d56a401da669c4d71c23c68b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50b85edb71ca4521a1dc5e8acf004bd3","placeholder":"​","style":"IPY_MODEL_806012a996354c1399b3256ce89da829","value":" 1.36M/1.36M [00:00&lt;00:00, 4.13MB/s]"}},"157642762f804d43890a7d866fb0d992":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1ede85a601b4f64866afa3aa753fcf6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9dc2373d7b34405495ad06239c22c7c1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b2d736c27af04a8e9c716fcbd6fe5ea9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0179de6eb51f4900aae73b9cd593a6c7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"50b85edb71ca4521a1dc5e8acf004bd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"806012a996354c1399b3256ce89da829":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"807cee8394554bc4a2f090cd2d857ced":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_634c3e62a49243e9b694683b6e3c361a","IPY_MODEL_ebe343b8a19b458d85e8f48689a2f585","IPY_MODEL_9d2e162bd77441058e474251365974c1"],"layout":"IPY_MODEL_31b66def87b341c2aa96d1130d9fe196"}},"634c3e62a49243e9b694683b6e3c361a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3076251976649a0be9ba64fb340b62b","placeholder":"​","style":"IPY_MODEL_300b081459064d8d977cc5d2e58f2ced","value":"config.json: 100%"}},"ebe343b8a19b458d85e8f48689a2f585":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_336e8741694b4f26825622cb1310c1e2","max":762,"min":0,"orientation":"horizontal","style":"IPY_MODEL_17265f732fb4445bb6eb1c9736473194","value":762}},"9d2e162bd77441058e474251365974c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e64952458554c69a791e484de3a617d","placeholder":"​","style":"IPY_MODEL_53f8d917da7940f889be5baf54aa6fc2","value":" 762/762 [00:00&lt;00:00, 23.3kB/s]"}},"31b66def87b341c2aa96d1130d9fe196":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3076251976649a0be9ba64fb340b62b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"300b081459064d8d977cc5d2e58f2ced":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"336e8741694b4f26825622cb1310c1e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17265f732fb4445bb6eb1c9736473194":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2e64952458554c69a791e484de3a617d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53f8d917da7940f889be5baf54aa6fc2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f3989ae7c64b445cbd11ba4095b1502e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_acbe8a145d9f41548c10565be7bf45d0","IPY_MODEL_1a0321f380194595b304485f6e2fb97d","IPY_MODEL_3f62cfdcbe60482791cd4897ecaa3760"],"layout":"IPY_MODEL_6cfde58b13b44ba0b7d6e0a6ed10ae2e"}},"acbe8a145d9f41548c10565be7bf45d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c43be013339b4dc889617999b90bd3a3","placeholder":"​","style":"IPY_MODEL_4e9e3a508c6542449e5c13fa22eb96af","value":"model.safetensors: 100%"}},"1a0321f380194595b304485f6e2fb97d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec8101ccb9e343ca959b8e90bf29d589","max":352824413,"min":0,"orientation":"horizontal","style":"IPY_MODEL_43f8a3344c9541d2820a70ee3bdb48b3","value":352824413}},"3f62cfdcbe60482791cd4897ecaa3760":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27b401b98ba343cd93aec88dba5e63b6","placeholder":"​","style":"IPY_MODEL_2e3f406a87c7458d926fd547fda02fdd","value":" 353M/353M [00:07&lt;00:00, 30.9MB/s]"}},"6cfde58b13b44ba0b7d6e0a6ed10ae2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c43be013339b4dc889617999b90bd3a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e9e3a508c6542449e5c13fa22eb96af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec8101ccb9e343ca959b8e90bf29d589":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43f8a3344c9541d2820a70ee3bdb48b3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"27b401b98ba343cd93aec88dba5e63b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e3f406a87c7458d926fd547fda02fdd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a975d88625284beb8f30eaa1bcc82153":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9c6731d8aa404c59b7f14b712ec0b532","IPY_MODEL_97abe1da7dfe460e99276d9d0528139c","IPY_MODEL_a6a1da73bcbc40d98d93fd443c4df9af"],"layout":"IPY_MODEL_dad2b4abb3894ec09d5bc3b59ac9a32f"}},"9c6731d8aa404c59b7f14b712ec0b532":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91c36724c01546bcbd0b835f9bfbd8e8","placeholder":"​","style":"IPY_MODEL_a289cb4727534e6fbb476847c8e49b3f","value":"generation_config.json: 100%"}},"97abe1da7dfe460e99276d9d0528139c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f9f35e111424b268c787ae7dccebd79","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6e7e7ef5c459472c82e8b3444adc101a","value":124}},"a6a1da73bcbc40d98d93fd443c4df9af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_44700135f18748e79b2aa5e26cf3de52","placeholder":"​","style":"IPY_MODEL_917b0dac04e14371ab5efa1818f9c635","value":" 124/124 [00:00&lt;00:00, 6.01kB/s]"}},"dad2b4abb3894ec09d5bc3b59ac9a32f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91c36724c01546bcbd0b835f9bfbd8e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a289cb4727534e6fbb476847c8e49b3f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f9f35e111424b268c787ae7dccebd79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e7e7ef5c459472c82e8b3444adc101a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"44700135f18748e79b2aa5e26cf3de52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"917b0dac04e14371ab5efa1818f9c635":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"XyuFSQGWlMrD"}},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AutoTokenizer, GPT2LMHeadModel, GPT2Tokenizer\n","from transformers import BertTokenizer, BertForSequenceClassification, T5Tokenizer, T5ForConditionalGeneration\n","from huggingface_hub import login\n","import torch"],"metadata":{"id":"mJQSWTpCxjb2","executionInfo":{"status":"ok","timestamp":1717016366860,"user_tz":-210,"elapsed":2233,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["project_path = '/content/drive/MyDrive/Colab Notebooks/RAG'"],"metadata":{"id":"5wT2fvm20bmm","executionInfo":{"status":"ok","timestamp":1717090707626,"user_tz":-210,"elapsed":452,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# GPU"],"metadata":{"id":"-51Pl889lKDn"}},{"cell_type":"code","source":["\n","print(torch.cuda.is_available())\n","# print(torch.cuda.get_device_name(0))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zd5YQ-IfoDFN","executionInfo":{"status":"ok","timestamp":1717016368732,"user_tz":-210,"elapsed":4,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"eac3c260-5827-4be2-9c45-5eaec7a036d5"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["False\n"]}]},{"cell_type":"markdown","source":["# Hugging Face Login"],"metadata":{"id":"dPnOa3oLlRy2"}},{"cell_type":"code","source":["# Log in using your Hugging Face access token\n","access_token = \"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\"\n","login(access_token)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6QvoS3g0665l","executionInfo":{"status":"ok","timestamp":1717016371594,"user_tz":-210,"elapsed":1002,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"0c985e43-d03a-40af-d778-8b9ff17ac76b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: read).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}]},{"cell_type":"markdown","source":["# Download LLM Models"],"metadata":{"id":"2GeI9iQqlWZO"}},{"cell_type":"markdown","source":["## GPT2"],"metadata":{"id":"ZYwTYbQ8ob4c"}},{"cell_type":"code","source":["model_name = \"gpt2\"\n","\n","tokenizer = GPT2Tokenizer.from_pretrained(model_name, use_auth_token=access_token)\n","model = GPT2LMHeadModel.from_pretrained(model_name, use_auth_token=access_token)\n","\n","model_save_path = f\"{project_path}/models/gpt2\"\n","\n","tokenizer.save_pretrained(model_save_path)\n","model.save_pretrained(model_save_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hMIZraIF2C1w","executionInfo":{"status":"ok","timestamp":1716996008102,"user_tz":-210,"elapsed":14965,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"ea3daf13-73d1-4108-85c8-c9256601db71"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1974: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:3027: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["## distil-GPT2"],"metadata":{"id":"gZ3k1dqQob4d"}},{"cell_type":"code","source":["model_name = \"distilgpt2\"\n","\n","tokenizer = GPT2Tokenizer.from_pretrained(model_name, use_auth_token=access_token)\n","model = GPT2LMHeadModel.from_pretrained(model_name, use_auth_token=access_token)\n","\n","model_save_path = f\"{project_path}/models/distilgpt2\"\n","\n","tokenizer.save_pretrained(model_save_path)\n","model.save_pretrained(model_save_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":469,"referenced_widgets":["354ffd0f13104621bdfd29d52ed583c6","c46bb9b7bb4641f4b76f04a1c882f656","cdee9e82795b4b76a204cc103bae02f1","1874c3ef2c954362ab51debd01bae886","31a6f3a4f896410bbf23c74563918d56","1e40bd0faef24cb0b9a7ae556a3f5b31","901947eeb0f84d379bd33ab7a9e714a5","4d9ad60c4a044aca832ced81802df18e","869b9c3bd2c94403af32360dc803b6d9","7ea934501e804c8caa9200c2614e444e","3915cc231e434e9e9f14472a57f5e031","414b3a31d0b24fd49542ff064dd819e5","303d11d5228842aba90b2891dff425af","ad3685c1507d460a8b519f02a020293d","1c8f02f95e1f4a359189c7ad17ee96a1","c571d9764d5f48babca37e3ec093826d","a79e48d41fe64295b4f85b58b2d7184d","844efac858254dfdb3270f899027705b","f4bf152acc144d9493769568e7f50a18","1ba3af30219845f8b445bcd15a420186","fa5eed0f38a6457cb655e6b255bc84e8","f14e682676c04c348661a560b54a554a","6515cd6c73aa4e07bb4762a7fe7eb0b1","f7aa5d52ce60467ea0f410fb58507dab","02835790a73340edb2acbc3f18ac289f","d50b6ea43d8543f1b64dd16bc4a9ee51","1d6e8ec5bc104e50a5e1fe9129104f9f","23b3ac7edeae4762a50821fc76b9b2b3","1d6018e6756b43138958199de5380fca","52b90cb98d81405a8ef0519caec18403","94133e9978104669a6c03327e4e6c2e1","d65493e278a34e8cbd431dd0202b9f34","2c9b278a655341478438e2defe9d61b7","392bab628ad74647a550f360623e5fd3","bf25aead1cb34520bafddaef004f8f40","8b5f2b9969e04f2aa46ac85d1dc4b112","527663a6d56a401da669c4d71c23c68b","157642762f804d43890a7d866fb0d992","b1ede85a601b4f64866afa3aa753fcf6","9dc2373d7b34405495ad06239c22c7c1","b2d736c27af04a8e9c716fcbd6fe5ea9","0179de6eb51f4900aae73b9cd593a6c7","50b85edb71ca4521a1dc5e8acf004bd3","806012a996354c1399b3256ce89da829","807cee8394554bc4a2f090cd2d857ced","634c3e62a49243e9b694683b6e3c361a","ebe343b8a19b458d85e8f48689a2f585","9d2e162bd77441058e474251365974c1","31b66def87b341c2aa96d1130d9fe196","d3076251976649a0be9ba64fb340b62b","300b081459064d8d977cc5d2e58f2ced","336e8741694b4f26825622cb1310c1e2","17265f732fb4445bb6eb1c9736473194","2e64952458554c69a791e484de3a617d","53f8d917da7940f889be5baf54aa6fc2","f3989ae7c64b445cbd11ba4095b1502e","acbe8a145d9f41548c10565be7bf45d0","1a0321f380194595b304485f6e2fb97d","3f62cfdcbe60482791cd4897ecaa3760","6cfde58b13b44ba0b7d6e0a6ed10ae2e","c43be013339b4dc889617999b90bd3a3","4e9e3a508c6542449e5c13fa22eb96af","ec8101ccb9e343ca959b8e90bf29d589","43f8a3344c9541d2820a70ee3bdb48b3","27b401b98ba343cd93aec88dba5e63b6","2e3f406a87c7458d926fd547fda02fdd","a975d88625284beb8f30eaa1bcc82153","9c6731d8aa404c59b7f14b712ec0b532","97abe1da7dfe460e99276d9d0528139c","a6a1da73bcbc40d98d93fd443c4df9af","dad2b4abb3894ec09d5bc3b59ac9a32f","91c36724c01546bcbd0b835f9bfbd8e8","a289cb4727534e6fbb476847c8e49b3f","1f9f35e111424b268c787ae7dccebd79","6e7e7ef5c459472c82e8b3444adc101a","44700135f18748e79b2aa5e26cf3de52","917b0dac04e14371ab5efa1818f9c635"]},"id":"HDL0UUQKoxBD","executionInfo":{"status":"ok","timestamp":1717007929092,"user_tz":-210,"elapsed":14884,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"e57862eb-77b5-4f52-bb11-b1d2b2a85d70"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1974: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"354ffd0f13104621bdfd29d52ed583c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"414b3a31d0b24fd49542ff064dd819e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6515cd6c73aa4e07bb4762a7fe7eb0b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"392bab628ad74647a550f360623e5fd3"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"807cee8394554bc4a2f090cd2d857ced"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:3027: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3989ae7c64b445cbd11ba4095b1502e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a975d88625284beb8f30eaa1bcc82153"}},"metadata":{}}]},{"cell_type":"markdown","source":["## T5"],"metadata":{"id":"LW_t4jSGob4e"}},{"cell_type":"code","source":["model_name = \"t5-small\"\n","\n","tokenizer = T5Tokenizer.from_pretrained(model_name)\n","model = T5ForConditionalGeneration.from_pretrained(model_name)\n","\n","model_save_path = f\"{project_path}/models/t5-small\"\n","\n","tokenizer.save_pretrained(model_save_path)\n","model.save_pretrained(model_save_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WFHlcN70qpgg","executionInfo":{"status":"ok","timestamp":1717011643611,"user_tz":-210,"elapsed":5925,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"7c9c87dc-ac5f-4aba-a71b-df7d68e30fcd"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"markdown","source":["## Bert"],"metadata":{"id":"WKK8YN0mJ8Vv"}},{"cell_type":"code","source":["model_name = \"bert-base-uncased\"\n","\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n","model = BertForSequenceClassification.from_pretrained(model_name)\n","\n","model_save_path = f\"{project_path}/models/bert-base-uncased\"\n","\n","tokenizer.save_pretrained(model_save_path)\n","model.save_pretrained(model_save_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vre2SIkQJJEP","executionInfo":{"status":"ok","timestamp":1717016384349,"user_tz":-210,"elapsed":7153,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"3634957b-292d-4718-9763-7e3d873e19d5"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"markdown","source":["# Import LLM Models"],"metadata":{"id":"Tuhng7F8lcqf"}},{"cell_type":"markdown","source":["## GPT2"],"metadata":{"id":"hx_xpuAVnaR-"}},{"cell_type":"code","source":["model_save_path = f\"{project_path}/models/gpt2\"\n","\n","# Load the model and tokenizer from Google Drive\n","tokenizer = GPT2Tokenizer.from_pretrained(model_save_path)\n","model = GPT2LMHeadModel.from_pretrained(model_save_path)\n","\n","# Check if GPU is available\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# Move the model to GPU\n","model.to(device)\n","\n","def generate_text(input_text):\n","    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n","    output = model.generate(input_ids, max_length=100, num_return_sequences=1, do_sample=True, top_k=50, top_p=0.95, temperature=0.7)\n","    return tokenizer.decode(output[0], skip_special_tokens=True)"],"metadata":{"id":"hS2PLGIZ8SfO","executionInfo":{"status":"ok","timestamp":1717016835456,"user_tz":-210,"elapsed":1964,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["input_text = \"Once upon a time\"\n","print(\"Generated Output:\", generate_text(input_text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dAjJdoyItDdZ","executionInfo":{"status":"ok","timestamp":1717016843562,"user_tz":-210,"elapsed":7594,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"0c90bb52-c446-45fc-c65f-03b8bdbda6a5"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["Generated Output: Once upon a time I thought of the'sniper' and 'hunter' as the two best people in the world. I was wrong. I was wrong about the 'dumb' and'sissy' part of the 'playboy' part. I was wrong about the 'dumb' and'sissy' part of the 'playboy' part. I was wrong about the 'dumb' and'sissy' part of the 'playboy' part. I was\n"]}]},{"cell_type":"markdown","source":["## distil-GPT2"],"metadata":{"id":"AEVVQ1opncl1"}},{"cell_type":"code","source":["model_save_path = f\"{project_path}/models/distilgpt2\"\n","\n","# Load the model and tokenizer from Google Drive\n","tokenizer = GPT2Tokenizer.from_pretrained(model_save_path)\n","model = GPT2LMHeadModel.from_pretrained(model_save_path)\n","\n","# Move the model to GPU\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","model.to(device)\n","\n","def generate_text(input_text):\n","    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n","    output = model.generate(input_ids, max_length=100, num_return_sequences=1, do_sample=True, top_k=50, top_p=0.95, temperature=0.7)\n","    return tokenizer.decode(output[0], skip_special_tokens=True)"],"metadata":{"id":"GxSy-pEhpDZn","executionInfo":{"status":"ok","timestamp":1717016924242,"user_tz":-210,"elapsed":6277,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Example usage\n","input_text = \"what are you?\"\n","print(\"Generated Output:\", generate_text(input_text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vNwLawUwpsEp","executionInfo":{"status":"ok","timestamp":1717016944400,"user_tz":-210,"elapsed":8855,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"7614168f-6bf4-4631-e76f-b5fad48bb5c1"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["Generated Output: what are you?”\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]}]},{"cell_type":"markdown","source":["## T5"],"metadata":{"id":"OhZ12_o1oQQf"}},{"cell_type":"code","source":["model_save_path = f\"{project_path}/models/t5-small\"\n","\n","# Load the model and tokenizer from Google Drive\n","tokenizer = T5Tokenizer.from_pretrained(model_save_path)\n","model = T5ForConditionalGeneration.from_pretrained(model_save_path)\n","\n","# Move the model to GPU\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","model.to(device)\n","\n","def generate_text(input_text):\n","    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n","    output = model.generate(input_ids, max_length=100, num_return_sequences=1, do_sample=True, top_k=50, top_p=0.95, temperature=0.7)\n","    return tokenizer.decode(output[0], skip_special_tokens=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kqQC5BrFq5AB","executionInfo":{"status":"ok","timestamp":1717011704362,"user_tz":-210,"elapsed":3412,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"ae32a3ae-ab06-4c2c-eab4-27b29bae68d0"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["# Example usage\n","input_text = \"Once upon a time\"\n","print(\"Generated Output:\", generate_text(input_text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"liI4CYlA2Nw8","executionInfo":{"status":"ok","timestamp":1717011707486,"user_tz":-210,"elapsed":417,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"691038e9-e3d7-454a-b113-f6e4c2ef92b5"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["Generated Output: Einemal\n"]}]},{"cell_type":"markdown","source":["## Bert"],"metadata":{"id":"frmlx4xRKVqd"}},{"cell_type":"code","source":["model_save_path = f\"{project_path}/models/bert-base-uncased\"\n","\n","tokenizer = BertTokenizer.from_pretrained(model_save_path)\n","model = BertForSequenceClassification.from_pretrained(model_save_path)\n","\n","# model_save_path = f\"{project_path}/models/bert-base-uncased\"\n","# # Load the model and tokenizer from Google Drive\n","# tokenizer = T5Tokenizer.from_pretrained(model_save_path)\n","# model = T5ForConditionalGeneration.from_pretrained(model_save_path)\n","\n","# Move the model to GPU\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","model.to(device)\n","\n","def classify_text_bert(input_text):\n","    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n","    outputs = model(input_ids)\n","    logits = outputs.logits\n","    predicted_class = logits.argmax().item()\n","    return predicted_class\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QprpF_oKKXVp","executionInfo":{"status":"ok","timestamp":1717016680814,"user_tz":-210,"elapsed":2646,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"289bebd4-13c6-478c-a795-6ac86b3be5e1"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Class: 1\n"]}]},{"cell_type":"code","source":["# Example usage\n","input_text = \"ttttttttttt ff sfsfsf, 42424!\"\n","print(\"Predicted Class:\", classify_text_bert(input_text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KlgsTcReK2zK","executionInfo":{"status":"ok","timestamp":1717016721086,"user_tz":-210,"elapsed":402,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"3db3b2a0-880f-483c-b3b0-5ac24e2412f6"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Class: 1\n"]}]},{"cell_type":"code","source":["class LLM:\n","  def __init__(self, llm_type):\n","    self.tokenizer, self.model = self.load_llm(llm_type)\n","    device = self.select_device()\n","    self.model.to(device)\n","\n","  def load_llm(self, llm_type):\n","    if llm_type == 'gpt2':\n","      model_path = f\"{project_path}/models/gpt2\"\n","      tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n","      model = GPT2LMHeadModel.from_pretrained(model_path)\n","\n","    elif llm_type == 'distilgpt2':\n","      model_path = f\"{project_path}/models/distilgpt2\"\n","      tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n","      model = GPT2LMHeadModel.from_pretrained(model_path)\n","\n","    elif llm_type == 't5-small':\n","      model_path = f\"{project_path}/models/t5-small\"\n","      tokenizer = T5Tokenizer.from_pretrained(model_path)\n","      model = T5ForConditionalGeneration.from_pretrained(model_path)\n","\n","    else:\n","      raise ValueError(f'the {llm_type} is not supported')\n","    return tokenizer, model\n","\n","  def select_device(self):\n","    return ('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","  def generate_text(self, input_text):\n","    input_ids = self.tokenizer.encode(input_text, return_tensors='pt').to(device)\n","    output = self.model.generate(input_ids, max_length=100, num_return_sequences=1, do_sample=True, top_k=50, top_p=0.95, temperature=0.7)\n","    return self.tokenizer.decode(output[0], skip_special_tokens=True)"],"metadata":{"id":"9vI78YRe4Dz-","executionInfo":{"status":"ok","timestamp":1717015939603,"user_tz":-210,"elapsed":417,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":99,"outputs":[]},{"cell_type":"markdown","source":["# LLM"],"metadata":{"id":"_com4NubP5Jv"}},{"cell_type":"code","source":["import logging\n","from transformers import (\n","    GPT2Tokenizer, GPT2LMHeadModel, T5Tokenizer, T5ForConditionalGeneration,\n","    BertTokenizer, BertForMaskedLM, DistilBertTokenizer, DistilBertForMaskedLM,\n","    RobertaTokenizer, RobertaForMaskedLM, GPTNeoForCausalLM\n",")\n","import torch\n","\n","class LLM:\n","    def __init__(self, llm_type: str, load_online=False):\n","        \"\"\"\n","        Initializes the LLM with the specified type and optional custom model path.\n","\n","        :param llm_type: The type of the language model (e.g., 'gpt2', 'distilgpt2', 't5-small', 'bert', 'distilbert', 'roberta', 'gpt-neo').\n","        \"\"\"\n","        self.device = self.select_device()\n","        if not load_online:\n","            self.tokenizer, self.model = self.load_llm_local(llm_type)\n","        else:\n","            self.tokenizer, self.model = self.load_llm_online(llm_type)\n","        self.model.to(self.device)\n","        logging.basicConfig(level=logging.INFO)\n","        logging.info(f\"Model {llm_type} loaded and moved to {self.device}.\")\n","\n","    def load_llm_local(self, llm_type: str):\n","        \"\"\"\n","        Loads the tokenizer and model based on the specified type and optional custom model path.\n","\n","        :param llm_type: The type of the language model.\n","        :return: A tuple of the tokenizer and model.\n","        \"\"\"\n","        try:\n","            if llm_type == 'gpt2':\n","                model_path = f\"{project_path}/models/gpt2\"\n","                tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n","                model = GPT2LMHeadModel.from_pretrained(model_path)\n","            elif llm_type == 'distilgpt2':\n","                model_path = f\"{project_path}/models/distilgpt2\"\n","                tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n","                model = GPT2LMHeadModel.from_pretrained(model_path)\n","            elif llm_type == 't5-small':\n","                model_path = f\"{project_path}/models/t5-small\"\n","                tokenizer = T5Tokenizer.from_pretrained(model_path)\n","                model = T5ForConditionalGeneration.from_pretrained(model_path)\n","            elif llm_type == 'bert':\n","                model_path = f\"{project_path}/models/bert\"\n","                tokenizer = BertTokenizer.from_pretrained(model_path)\n","                model = BertForMaskedLM.from_pretrained(model_path)\n","            elif llm_type == 'distilbert':\n","                model_path = f\"{project_path}/models/distilbert\"\n","                tokenizer = DistilBertTokenizer.from_pretrained(model_path)\n","                model = DistilBertForMaskedLM.from_pretrained(model_path)\n","            elif llm_type == 'roberta':\n","                model_path = f\"{project_path}/models/roberta\"\n","                tokenizer = RobertaTokenizer.from_pretrained(model_path)\n","                model = RobertaForMaskedLM.from_pretrained(model_path)\n","            elif llm_type == 'gpt-neo':\n","                model_path = f\"{project_path}/models/gpt-neo\"\n","                tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n","                model = GPTNeoForCausalLM.from_pretrained(model_path)\n","            else:\n","                raise ValueError(f\"Unsupported model type: {llm_type}\")\n","            return tokenizer, model\n","        except Exception as e:\n","            logging.error(f\"Error loading model {llm_type} from {model_path}: {e}\")\n","            raise\n","    def load_llm_online(self, llm_type: str):\n","        \"\"\"\n","        Loads the tokenizer and model based on the specified type and optional custom model path.\n","\n","        :param llm_type: The type of the language model.\n","        :return: A tuple of the tokenizer and model.\n","        \"\"\"\n","        try:\n","            if llm_type == 'gpt2':\n","                model_path = \"gpt2\"\n","                tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n","                model = GPT2LMHeadModel.from_pretrained(model_path)\n","            elif llm_type == 'distilgpt2':\n","                model_path = \"distilgpt2\"\n","                tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n","                model = GPT2LMHeadModel.from_pretrained(model_path)\n","            elif llm_type == 't5-small':\n","                model_path = \"t5-small\"\n","                tokenizer = T5Tokenizer.from_pretrained(model_path)\n","                model = T5ForConditionalGeneration.from_pretrained(model_path)\n","            elif llm_type == 'bert':\n","                model_path = \"bert-base-uncased\"\n","                tokenizer = BertTokenizer.from_pretrained(model_path)\n","                model = BertForMaskedLM.from_pretrained(model_path)\n","            elif llm_type == 'distilbert':\n","                model_path = \"distilbert-base-uncased\"\n","                tokenizer = DistilBertTokenizer.from_pretrained(model_path)\n","                model = DistilBertForMaskedLM.from_pretrained(model_path)\n","            elif llm_type == 'roberta':\n","                model_path = \"roberta-base\"\n","                tokenizer = RobertaTokenizer.from_pretrained(model_path)\n","                model = RobertaForMaskedLM.from_pretrained(model_path)\n","            elif llm_type == 'gpt-neo':\n","                model_path = \"EleutherAI/gpt-neo-125M\"\n","                tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n","                model = GPTNeoForCausalLM.from_pretrained(model_path)\n","            else:\n","                raise ValueError(f\"Unsupported model type: {llm_type}\")\n","            return tokenizer, model\n","        except Exception as e:\n","            logging.error(f\"Error loading model {llm_type} from {model_path}: {e}\")\n","            raise\n","\n","    @staticmethod\n","    def select_device() -> str:\n","        \"\"\"\n","        Selects the appropriate device (CUDA or CPU) for model inference.\n","\n","        :return: The device ('cuda' or 'cpu').\n","        \"\"\"\n","        return 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","    def generate_text(self, input_text: str) -> str:\n","        \"\"\"\n","        Generates text based on the input text using the loaded language model.\n","\n","        :param input_text: The input text prompt.\n","        :return: The generated text.\n","        \"\"\"\n","        try:\n","            input_ids = self.tokenizer.encode(input_text, return_tensors='pt').to(self.device)\n","            output = self.model.generate(\n","                input_ids, max_length=100, num_return_sequences=1,\n","                do_sample=True, top_k=50, top_p=0.95, temperature=0.7\n","            )\n","            return self.tokenizer.decode(output[0], skip_special_tokens=True)\n","        except Exception as e:\n","            logging.error(f\"Error generating text for input '{input_text}': {e}\")\n","            return \"Error generating text.\"\n","\n"],"metadata":{"id":"DRAdIqF3kqJo","executionInfo":{"status":"ok","timestamp":1717101848197,"user_tz":-210,"elapsed":366,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["class RAG:\n","  def __init__(self):\n","    pass\n","\n"],"metadata":{"id":"Dws6-d7g-4Ga"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# llm = LLM('gpt2')\n","llm = LLM('distilgpt2')\n","# llm = LLM('t5-small')"],"metadata":{"id":"l1mNxSihDEBH","executionInfo":{"status":"ok","timestamp":1717015941880,"user_tz":-210,"elapsed":1292,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":100,"outputs":[]},{"cell_type":"code","source":["output = llm.generate_text('tell me a story')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o1iEpkD2DL3u","executionInfo":{"status":"ok","timestamp":1717015944891,"user_tz":-210,"elapsed":3015,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"7dc7fbf9-5d09-4480-bbb3-954e0f1a42d6"},"execution_count":101,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]}]},{"cell_type":"code","source":["print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qLpMSG15Ec6T","executionInfo":{"status":"ok","timestamp":1717015944892,"user_tz":-210,"elapsed":6,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"4a8de3f4-f97e-4684-d581-a23fe98537cb"},"execution_count":102,"outputs":[{"output_type":"stream","name":"stdout","text":["tell me a story, and we will be doing it.”\n","\n","\n","“\n"]}]},{"cell_type":"code","source":["!pip uninstall -q chromadb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_KD2kLBiTEfK","executionInfo":{"status":"ok","timestamp":1717059982198,"user_tz":-210,"elapsed":5996,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"a1af7337-bd76-4a25-9211-bd8f478e3929"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Proceed (Y/n)? y\n"]}]},{"cell_type":"code","source":["!pip install -q chromadb"],"metadata":{"id":"eA0eZOdiwAPq","executionInfo":{"status":"ok","timestamp":1717060013809,"user_tz":-210,"elapsed":19559,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["!pip install -q chromadb sentence-transformers"],"metadata":{"id":"kWYndIc8QAfJ","executionInfo":{"status":"ok","timestamp":1717059879969,"user_tz":-210,"elapsed":9849,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["!pip install sentence-transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RBHr72hXUXXU","executionInfo":{"status":"ok","timestamp":1717019250880,"user_tz":-210,"elapsed":56205,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"34568ba1-a329-4854-928b-a88fbfc40c5d"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sentence-transformers\n","  Using cached sentence_transformers-3.0.0-py3-none-any.whl (224 kB)\n","Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.41.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.4)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.3.0+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.23.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.14.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.5.40)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Installing collected packages: nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers\n","Successfully installed nvidia-cudnn-cu12-8.9.2.26 nvidia-cusolver-cu12-11.4.5.107 sentence-transformers-3.0.0\n"]}]},{"cell_type":"code","source":["from chromadb import Client, Settings\n","from sentence_transformers import SentenceTransformer\n","\n","# Initialize ChromaDB client\n","client = Client(Settings())\n","\n","# Define a collection for storing contexts\n","collection = client.get_or_create_collection(\"qa_contexts\")\n","\n","# Initialize the sentence transformer model for vectorization\n","vectorizer = SentenceTransformer('all-MiniLM-L6-v2')\n","\n","# Sample context data\n","context_data = [\n","    \"The capital of France is Paris. It is known for its art, culture, and cuisine.\",\n","    \"The Great Wall of China is one of the greatest wonders of the world.\",\n","    \"The Amazon rainforest is a moist broadleaf forest that covers most of the Amazon basin of South America.\"\n","]\n","\n","# Vectorize the context data\n","vectors = vectorizer.encode(context_data, convert_to_tensor=True)\n","\n","# Generate unique IDs for each context\n","ids = [f\"context_{i}\" for i in range(len(context_data))]\n","\n","# Add vectors and context data to ChromaDB\n","collection.add(ids=ids, embeddings=vectors.tolist(), documents=context_data)\n","\n","# Now let's define functions to retrieve context and answer questions\n","from transformers import T5Tokenizer, T5ForConditionalGeneration\n","import torch\n","\n","# Load the model and tokenizer\n","model_name = \"t5-small\"\n","tokenizer = T5Tokenizer.from_pretrained(model_name)\n","model = T5ForConditionalGeneration.from_pretrained(model_name)\n","\n","# Check if GPU is available\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","model.to(device)\n","\n","def retrieve_context(question):\n","    # Vectorize the question\n","    question_vector = vectorizer.encode([question], convert_to_tensor=True)[0]\n","    # Find the most similar context in the collection\n","    results = collection.query(query_embeddings=[question_vector.tolist()], n_results=1)\n","    return results['documents'][0]\n","\n","def answer_question_t5(question):\n","    context = retrieve_context(question)\n","    input_text = f\"question: {question} context: {context}\"\n","    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n","\n","    # Generate answer\n","    with torch.no_grad():\n","        output = model.generate(input_ids, max_length=150)\n","\n","    # Decode the generated text\n","    answer = tokenizer.decode(output[0], skip_special_tokens=True)\n","    return answer.strip()\n","\n","# Example usage\n","question = \"What is the capital of France?\"\n","print(\"Generated Answer:\", answer_question_t5(question))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rQJF8IiFP44w","executionInfo":{"status":"ok","timestamp":1717019644854,"user_tz":-210,"elapsed":3353,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"770e40c0-7249-4e49-bf5a-2ae8709dcf79"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: context_0\n","WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: context_1\n","WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: context_2\n","WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: context_0\n","WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: context_1\n","WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: context_2\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"stream","name":"stdout","text":["Generated Answer: Paris\n"]}]},{"cell_type":"code","source":["from chromadb import Client, Settings\n","from sentence_transformers import SentenceTransformer\n","\n","# Initialize ChromaDB client\n","client = Client(Settings())\n","\n","# Define a collection for storing contexts\n","collection = client.get_or_create_collection(\"qa_contexts\")\n","\n","# Initialize the sentence transformer model for vectorization\n","vectorizer = SentenceTransformer('all-MiniLM-L6-v2')\n","\n","# Sample context data\n","context_data = [\n","    \"The capital of France is Paris. It is known for its art, culture, and cuisine.\",\n","    \"The Great Wall of China is one of the greatest wonders of the world.\",\n","    \"The Amazon rainforest is a moist broadleaf forest that covers most of the Amazon basin of South America.\",\n","    \"The Amazon rainforest is a moist broadleaf forest that covers most of the Amazon basin of South asia.\"\n","]\n","\n","# Vectorize the context data\n","vectors = vectorizer.encode(context_data)\n","\n","# Generate unique IDs for each context\n","ids = [f\"context_{i}\" for i in range(len(context_data))]\n","\n","# Add vectors and context data to ChromaDB\n","collection.add(ids=ids, embeddings=vectors.tolist(), documents=context_data)\n","\n","print(\"Documents added to ChromaDB.\")\n","class Collection:\n","  def __init__(self):\n","    pass\n","\n","  def add_docs(self, docs):\n","    pass\n","\n","  def vectorizer(self, docs):\n","    pass\n","\n",""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_1E-Wu7YtmAI","executionInfo":{"status":"ok","timestamp":1717065128139,"user_tz":-210,"elapsed":561,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"a4069561-b04e-4c60-f628-895226a8abe5"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: context_0\n","WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: context_1\n","WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: context_2\n","WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: context_0\n","WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: context_1\n","WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: context_2\n"]},{"output_type":"stream","name":"stdout","text":["Documents added to ChromaDB.\n"]}]},{"cell_type":"code","source":["from transformers import T5Tokenizer, T5ForConditionalGeneration\n","import torch\n","\n","# Load the model and tokenizer\n","model_name = \"t5-small\"\n","tokenizer = T5Tokenizer.from_pretrained(model_name)\n","model = T5ForConditionalGeneration.from_pretrained(model_name)\n","\n","# Check if GPU is available\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","model.to(device)\n","\n","def retrieve_context(question):\n","    # Vectorize the question\n","    question_vector = vectorizer.encode([question])[0].tolist()\n","    # Find the most similar context in the collection\n","    results = collection.query(query_embeddings=[question_vector], n_results=1)\n","    return results['documents'][0]\n","\n","def answer_question_t5(question):\n","    context = retrieve_context(question)\n","    input_text = f\"question: {question} context: {context}\"\n","    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n","\n","    # Generate answer\n","    with torch.no_grad():\n","        output = model.generate(input_ids, max_length=150)\n","\n","    # Decode the generated text\n","    answer = tokenizer.decode(output[0], skip_special_tokens=True)\n","    return answer.strip()\n","\n","# Example usage\n","question = \"the\"\n","print(\"Generated Answer:\", answer_question_t5(question))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UKA1IfExtpaU","executionInfo":{"status":"ok","timestamp":1717065178652,"user_tz":-210,"elapsed":4580,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"8fc4b333-db20-480a-c38d-3d16d5ed99a5"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"stream","name":"stdout","text":["{'ids': [['context_3']], 'distances': [[1.8912122249603271]], 'metadatas': [[None]], 'embeddings': None, 'documents': [['The Amazon rainforest is a moist broadleaf forest that covers most of the Amazon basin of South asia.']], 'uris': None, 'data': None}\n","['The Amazon rainforest is a moist broadleaf forest that covers most of the Amazon basin of South asia.']\n","Generated Answer: ['The Amazon rainforest is a moist broadleaf forest that covers most of the Amazon basin of South asia\n"]}]},{"cell_type":"code","source":["def rag_system(question, top_n=1):\n","    context = retrieve_context(question)\n","    input_text = f\"question: {question} context: {context}\"\n","    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n","\n","    # Generate answer\n","    with torch.no_grad():\n","        output = model.generate(input_ids, max_length=150)\n","\n","    # Decode the generated text\n","    answer = tokenizer.decode(output[0], skip_special_tokens=True)\n","    return answer.strip()\n","\n","# Example usage\n","question = \"What is the capital of France?\"\n","response = rag_system(question)\n","print(\"Generated Answer:\", response)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FbMiiUyaz_EN","executionInfo":{"status":"ok","timestamp":1717065003619,"user_tz":-210,"elapsed":467,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"890c9175-76f0-4e6c-a985-1c5d5b0119de"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["{'ids': [['context_0']], 'distances': [[0.44983717799186707]], 'metadatas': [[None]], 'embeddings': None, 'documents': [['The capital of France is Paris. It is known for its art, culture, and cuisine.']], 'uris': None, 'data': None}\n","Generated Answer: Paris\n"]}]},{"cell_type":"code","source":["# Example usage\n","question = \"the\"\n","response = rag_system(question)\n","print(\"Generated Answer:\", response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2XK9L8HK5OP5","executionInfo":{"status":"ok","timestamp":1717065040760,"user_tz":-210,"elapsed":1184,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"e4b8ebc2-6a18-4b08-ff4a-28ac80609c0e"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["{'ids': [['context_2']], 'distances': [[1.9055213928222656]], 'metadatas': [[None]], 'embeddings': None, 'documents': [['The Amazon rainforest is a moist broadleaf forest that covers most of the Amazon basin of South America.']], 'uris': None, 'data': None}\n","Generated Answer: ['The Amazon rainforest is a moist broadleaf forest that covers most of the Amazon basin of South America\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"lZ9Xway0-Z4g"},"execution_count":null,"outputs":[]}]}