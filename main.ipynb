{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1xGeaM-oFVeEliD38KtLRTtP4lPrQVkz-","authorship_tag":"ABX9TyMFvZR1+mUp6kkrw2ZB+2pt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"XyuFSQGWlMrD"}},{"cell_type":"code","source":["!pip install -q chromadb sentence-transformers"],"metadata":{"collapsed":true,"id":"xxPdB5Lm6zpx","executionInfo":{"status":"ok","timestamp":1717722255464,"user_tz":-210,"elapsed":21992,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["!pip install -q chromadb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T8AWjbKsIDL4","executionInfo":{"status":"ok","timestamp":1717669405776,"user_tz":-210,"elapsed":36632,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"4bfe6c54-a4a6-42a2-a667-5850509509ba"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.8/526.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n","weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!pip install -q langchain\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bS6oQJeVSRTH","executionInfo":{"status":"ok","timestamp":1717609462111,"user_tz":-210,"elapsed":9225,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"43a7c35d-195a-4b0b-df15-076807ba03ee"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.2)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.4)\n","Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.1)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.71)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.2)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (1.33)\n","Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (23.2)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.18.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.3)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (2.4)\n"]}]},{"cell_type":"code","source":["from huggingface_hub import login\n","import logging\n","from transformers import (\n","    GPT2Tokenizer, GPT2LMHeadModel, T5Tokenizer, T5ForConditionalGeneration,\n","    BertTokenizer, BertForQuestionAnswering, DistilBertTokenizer, DistilBertForQuestionAnswering,\n","    GPTNeoForCausalLM, pipeline\n",")\n","import torch\n","from chromadb import Client, Settings\n","from sentence_transformers import SentenceTransformer\n","import gc"],"metadata":{"id":"mJQSWTpCxjb2","executionInfo":{"status":"ok","timestamp":1717725602986,"user_tz":-210,"elapsed":466,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":102,"outputs":[]},{"cell_type":"code","source":["project_path = '/content/drive/MyDrive/Colab Notebooks/RAG'"],"metadata":{"id":"5wT2fvm20bmm","executionInfo":{"status":"ok","timestamp":1717722288498,"user_tz":-210,"elapsed":18,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# GPU"],"metadata":{"id":"-51Pl889lKDn"}},{"cell_type":"code","source":["\n","print(torch.cuda.is_available())\n","# print(torch.cuda.get_device_name(0))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zd5YQ-IfoDFN","executionInfo":{"status":"ok","timestamp":1717722288499,"user_tz":-210,"elapsed":19,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"a4693016-c3e3-46a6-9fb0-e16330bdffa3"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["False\n"]}]},{"cell_type":"markdown","source":["# Hugging Face Login"],"metadata":{"id":"dPnOa3oLlRy2"}},{"cell_type":"code","source":["# Log in using your Hugging Face access token\n","access_token = \"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\"\n","login(access_token)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6QvoS3g0665l","executionInfo":{"status":"ok","timestamp":1717722288499,"user_tz":-210,"elapsed":17,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"3745116d-38c3-43fa-d146-8c83ed650dce"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: read).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}]},{"cell_type":"markdown","source":["# LLM\n","\n","\n","---\n","\n","###key functions of LLM class:\n","\n","\n","*   **load_llm_local**: tries to load an llm from google drvie\n","*   **load_llm_online**: loads the llm from hugging face\n","*   **select_device**: if gpu is available it will select it\n","*   **generate_text**: it can generate text based on given prompt"],"metadata":{"id":"_com4NubP5Jv"}},{"cell_type":"code","source":["class LLM:\n","    model_classes = {\n","        'gpt2': (GPT2Tokenizer, GPT2LMHeadModel, 'gpt2'),\n","        't5': (T5Tokenizer, T5ForConditionalGeneration, 't5-small'),\n","        'bert': (BertTokenizer, BertForQuestionAnswering, 'bert-large-uncased-whole-word-masking-finetuned-squad'),\n","        'distil-bert': (DistilBertTokenizer, DistilBertForQuestionAnswering, 'distilbert-base-cased-distilled-squad'),\n","        'gpt-neo': (GPT2Tokenizer, GPTNeoForCausalLM, 'EleutherAI/gpt-neo-1.3B')\n","    }\n","    def __init__(self, llm_type: str, load_online=False, save_model=False):\n","        self.device = self.select_device()\n","        self.tokenizer, self.model = self.load_llm(llm_type, load_online, save_model)\n","        self.model.to(self.device)\n","        logging.basicConfig(level=logging.INFO)\n","        logging.info(f\"Model {llm_type} loaded and moved to {self.device}.\")\n","\n","    def load_llm(self, llm_type: str, load_online: bool, save_model: bool):\n","\n","        tokenizer_class, model_class, model_path = self.model_classes[llm_type]\n","\n","        if not load_online:\n","            model_path = f\"{project_path}/models/{model_path}\"\n","\n","        tokenizer = tokenizer_class.from_pretrained(model_path)\n","        model = model_class.from_pretrained(model_path)\n","\n","        if save_model:\n","            tokenizer.save_pretrained(f'{project_path}/models/{model_path}')\n","            model.save_pretrained(f'{project_path}/models/{model_path}')\n","\n","        return tokenizer, model\n","\n","\n","    @staticmethod\n","    def select_device() -> str:\n","        return 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","    def generate_text(self, input_text: str, context: str = '') -> str:\n","        raise NotImplementedError(\"The generate_text method should be implemented by the subclass.\")\n","\n","    def free_memory(self):\n","        del self.model\n","        del self.tokenizer\n","        gc.collect()\n","        torch.cuda.empty_cache()"],"metadata":{"id":"DRAdIqF3kqJo","executionInfo":{"status":"ok","timestamp":1717722432918,"user_tz":-210,"elapsed":383,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## GPT2"],"metadata":{"id":"mTRHbbc58yIz"}},{"cell_type":"code","source":["class GPT2(LLM):\n","    def __init__(self, load_online=False, save_model=False):\n","        super().__init__('gpt2', load_online, save_model)\n","\n","    def generate_text(self, input_text: str, context: str = '') -> str:\n","\n","        prompt = f\"Context: {context}\\nQuestion: {question}\\nAnswer:\"\n","        inputs = self.tokenizer.encode(prompt, return_tensors='pt')\n","        outputs = self.model.generate(\n","            inputs,\n","            max_length=80,\n","            temperature=0.7,\n","            top_p=0.9,\n","            top_k=50,\n","            num_return_sequences=1,\n","            pad_token_id=self.tokenizer.eos_token_id,\n","            do_sample=True\n","        )\n","\n","        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n","        response = response.replace(prompt, '').strip()\n","\n","        return response.split('\\n')[0]"],"metadata":{"id":"54UnFDdY9Hzl","executionInfo":{"status":"ok","timestamp":1717725435719,"user_tz":-210,"elapsed":342,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":91,"outputs":[]},{"cell_type":"markdown","source":["## t5"],"metadata":{"id":"bTjBZyNpEezi"}},{"cell_type":"code","source":["class T5(LLM):\n","    def __init__(self, load_online=False, save_model=False):\n","        super().__init__('t5', load_online, save_model)\n","\n","    def generate_text(self, input_text: str, context: str = None) -> str:\n","\n","        # prompt = f\"question: {input_text} context: {context}\"\n","        prompt = f\"question: {input_text} context: {context}\" if context else f\"question: {input_text}\"\n","        input_ids = self.tokenizer.encode(prompt, return_tensors='pt', max_length=512, truncation=True)\n","        outputs = self.model.generate(input_ids, max_length=50, num_beams=1, early_stopping=False)\n","        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","        return response"],"metadata":{"id":"CS6-G5GMEeDe","executionInfo":{"status":"ok","timestamp":1717722440694,"user_tz":-210,"elapsed":526,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["## BERT"],"metadata":{"id":"kZqUha0OG81c"}},{"cell_type":"code","source":["class BERT(LLM):\n","    def __init__(self, load_online=False, save_model=False):\n","        super().__init__('bert', load_online, save_model)\n","\n","    def generate_text(self, input_text: str, context: str = '') -> str:\n","\n","        nlp = pipeline('question-answering', model=self.model, tokenizer=self.tokenizer)\n","        result = nlp(question=input_text, context=context)\n","        return result['answer']"],"metadata":{"id":"00dae2leG-LT","executionInfo":{"status":"ok","timestamp":1717725608222,"user_tz":-210,"elapsed":337,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":103,"outputs":[]},{"cell_type":"markdown","source":["## Distil BERT"],"metadata":{"id":"YBkBRlkZJMPx"}},{"cell_type":"code","source":["class DistilBERT(LLM):\n","    def __init__(self, load_online=False, save_model=False):\n","        super().__init__('distil-bert', load_online, save_model)\n","\n","    def generate_text(self, input_text: str, context: str = '') -> str:\n","        nlp = pipeline('question-answering', model=self.model, tokenizer=self.tokenizer)\n","        result = nlp(question=input_text, context=context)\n","        return result['answer']"],"metadata":{"id":"muUrhJFlJOUU","executionInfo":{"status":"ok","timestamp":1717722444087,"user_tz":-210,"elapsed":1,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["## GPT-Neo"],"metadata":{"id":"Cme1-CrhLlJ2"}},{"cell_type":"code","source":["class NeoGPT(LLM):\n","    def __init__(self, load_online=False, save_model=False):\n","        super().__init__('gpt-neo', load_online, save_model)\n","\n","    def generate_text(self, input_text: str, context: str = None) -> str:\n","\n","        prompt = f\"question: {input_text} context: {context}\" if context else f\"question: {input_text}\"\n","\n","        inputs = self.tokenizer.encode(prompt, return_tensors='pt')\n","\n","        outputs = self.model.generate(\n","            inputs,\n","            max_length=100,\n","            num_return_sequences=1,\n","            pad_token_id=self.tokenizer.eos_token_id,\n","            num_beams=5,\n","            temperature=0.7,\n","            top_k=50,\n","            top_p=0.95,\n","            no_repeat_ngram_size=2,\n","            do_sample=True\n","        )\n","\n","        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n","        return response"],"metadata":{"id":"OlHq6oDMLnNc","executionInfo":{"status":"ok","timestamp":1717723414758,"user_tz":-210,"elapsed":336,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["## test LLM class"],"metadata":{"id":"Myfojpj6wtID"}},{"cell_type":"code","source":["llm = GPT2()"],"metadata":{"id":"sBG1ITO4-Dbk","executionInfo":{"status":"ok","timestamp":1717725442351,"user_tz":-210,"elapsed":2875,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":92,"outputs":[]},{"cell_type":"code","source":["# Example usage\n","question = \"What is the capital of Iran?\"\n","context = 'The capital of Iran is Tehran.'\n","\n","response = llm.generate_text(question, context)\n","print(\"response:\", response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-yTtMcNRODtk","executionInfo":{"status":"ok","timestamp":1717723500490,"user_tz":-210,"elapsed":7388,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"8d64ca50-a329-43c3-9b14-e5ba40676288"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["response: Tehran is the capital of Iran.\n"]}]},{"cell_type":"markdown","source":["# Collection"],"metadata":{"id":"LdexZkZ662Dt"}},{"cell_type":"code","source":["class Collection:\n","    def __init__(self, collection_name: str, transformer_type: str = 'all-MiniLM-L6-v2', load_online=False, save_transformer=False):\n","        self.client = Client(Settings())\n","        existing_collections = [col.name for col in self.client.list_collections()]\n","        if collection_name in existing_collections:\n","            self.client.delete_collection(collection_name)\n","        self.collection = self.client.get_or_create_collection(collection_name)\n","        self.vectorizer = self.load_sentence_transformer(transformer_type, load_online, save_transformer)\n","\n","    def load_sentence_transformer(self, transformer_type: str, load_online: bool, save_transformer: bool):\n","        transformer_path = f'{project_path}/models/{transformer_type}' if not load_online else transformer_type\n","        vectorizer = SentenceTransformer(transformer_path)\n","\n","        if save_transformer:\n","            vectorizer.save(f'{project_path}/models/{transformer_type}')\n","\n","        return vectorizer\n","\n","    def add_contexts(self, context_data: list):\n","        vectors = self.vectorizer.encode(context_data)\n","        ids = [f\"context_{i}\" for i in range(len(context_data))]\n","        self.collection.add(ids=ids, embeddings=vectors.tolist(), documents=context_data)\n","        print(\"Documents added to ChromaDB.\")\n","\n","    def retrieve_contexts(self, question: str, top_n: int = 1):\n","        question_vector = self.vectorizer.encode([question])[0].tolist()\n","        results = self.collection.query(query_embeddings=[question_vector], n_results=top_n)\n","        results = results['documents'][0]\n","        return results[:top_n]"],"metadata":{"id":"AQIdviiA6i4H","executionInfo":{"status":"ok","timestamp":1717725445663,"user_tz":-210,"elapsed":442,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":93,"outputs":[]},{"cell_type":"markdown","source":["## test Collection class"],"metadata":{"id":"ovlSNOQQwwPb"}},{"cell_type":"code","source":["# tranformer types:\n","\n","# default => all-MiniLM-L6-v2\n","# paraphrase-MiniLM-L6-v2\n","# paraphrase-xlm-r-multilingual-v1\n","# stsb-roberta-large"],"metadata":{"id":"DM5CKh11UQJ6","executionInfo":{"status":"ok","timestamp":1717724613158,"user_tz":-210,"elapsed":433,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["collection = Collection('rag')\n","\n","context_data = [\n","    \"The capital of France is Paris. It is known for its art, culture, and cuisine.\",\n","    \"The Great Wall of China is one of the greatest wonders of the world.\",\n","    \"The Amazon rainforest is a moist broadleaf forest that covers most of the Amazon basin of South America.\",\n","    \"The Amazon rainforest is a moist broadleaf forest that covers most of the Amazon basin of South Asia.\"\n","]\n","collection.add_contexts(context_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FzCnp-Znw47j","executionInfo":{"status":"ok","timestamp":1717725449822,"user_tz":-210,"elapsed":832,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"9603323a-4916-4095-f63a-a33a0d216bed"},"execution_count":94,"outputs":[{"output_type":"stream","name":"stdout","text":["Documents added to ChromaDB.\n"]}]},{"cell_type":"code","source":["response = collection.retrieve_contexts('amazon', top_n=2)\n","\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OYQlpAekWYzB","executionInfo":{"status":"ok","timestamp":1717725078630,"user_tz":-210,"elapsed":361,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"18cb85fa-3b44-4eea-f60e-33ca99ccb28f"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["['The Amazon rainforest is a moist broadleaf forest that covers most of the Amazon basin of South Asia.', 'The Amazon rainforest is a moist broadleaf forest that covers most of the Amazon basin of South America.']\n"]}]},{"cell_type":"markdown","source":["# RAG"],"metadata":{"id":"c-HzDeeB69UN"}},{"cell_type":"code","source":["class RAG:\n","    def __init__(self, llm: LLM, collection: Collection):\n","        self.llm = llm\n","        self.collection = collection\n","\n","    def generate_response(self, query: str, top_n: int=1) -> str:\n","        retrieved_contexts = self.collection.retrieve_contexts(query, top_n)\n","        retrieved_contexts = '\\n'.join(retrieved_contexts)\n","        response = self.llm.generate_text(query, retrieved_contexts)\n","        return response\n"],"metadata":{"id":"pRN9IYwTHNAN","executionInfo":{"status":"ok","timestamp":1717725617215,"user_tz":-210,"elapsed":365,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":104,"outputs":[]},{"cell_type":"markdown","source":["## test RAG class"],"metadata":{"id":"sNCKr-Kaw0NY"}},{"cell_type":"code","source":["llm = BERT()\n","collection = Collection('rag')\n","\n","context_data = [\n","    \"The capital of France is Paris. It is known for its art, culture, and cuisine.\",\n","    \"The Great Wall of China is one of the greatest wonders of the world.\",\n","    \"The Amazon rainforest is a moist broadleaf forest that covers most of the Amazon basin of South America.\",\n","    \"The Amazon rainforest is a moist broadleaf forest that covers most of the Amazon basin of South Asia.\"\n","]\n","collection.add_contexts(context_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jYTZaTUOHOc8","executionInfo":{"status":"ok","timestamp":1717725623048,"user_tz":-210,"elapsed":4114,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"b55a5c74-4df2-4433-f3ad-e34b8c4be438"},"execution_count":105,"outputs":[{"output_type":"stream","name":"stdout","text":["Documents added to ChromaDB.\n"]}]},{"cell_type":"code","source":["rag = RAG(llm, collection)"],"metadata":{"id":"2VmxmObZHpeb","executionInfo":{"status":"ok","timestamp":1717725660240,"user_tz":-210,"elapsed":347,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":108,"outputs":[]},{"cell_type":"code","source":["query = \"tell me about china?\"\n","response = rag.generate_response(query, top_n=3)\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EqIbl7bPbXrh","executionInfo":{"status":"ok","timestamp":1717725694762,"user_tz":-210,"elapsed":8523,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"31c532e8-2b67-4a9d-981d-01d6f01d37af"},"execution_count":110,"outputs":[{"output_type":"stream","name":"stdout","text":["The Great Wall of China is one of the greatest wonders of the world.\n"]}]},{"cell_type":"code","source":["from langchain_community.embeddings.sentence_transformer import (\n","    SentenceTransformerEmbeddings,\n",")\n","import chromadb\n","from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n","ef = SentenceTransformerEmbeddingFunction(model_name='all-MiniLM-L6-v2')\n","\n","chroma_client = chromadb.Client()\n","collection_name = \"marmikpandya\"\n","try:\n","    chroma_client.delete_collection(collection_name)\n","    print(f\"Deleted existing collection: {collection_name}\")\n","except Exception as e:\n","    print(f\"Collection {collection_name} does not exist or could not be deleted: {e}\")\n","\n","# Create the collection\n","collection = chroma_client.create_collection(name=collection_name, embedding_function=ef)\n","# collection = chroma_client.create_collection(name=\"marmikpandya\", embedding_function=ef)\n","context_data = [\n","    \"The capital of France is Paris. It is known for its art, culture, and cuisine.\",\n","    \"The Great Wall of China is one of the greatest wonders of the world.\",\n","    \"The Amazon rainforest is a moist broadleaf forest that covers most of the Amazon basin of South America.\",\n","    \"The Amazon rainforest is a moist broadleaf forest that covers most of the Amazon basin of South Asia.\"\n","]\n","collection.add(\n","    documents=context_data,\n","    # metadatas=[{\"response\": out} for out in dataset[\"train\"][\"output\"]],\n","    ids=[str(i) for i in range(len(context_data))]\n",")\n","chroma_client = chromadb.Client()\n","ef_lc = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n","langchain_chroma = Chroma(\n","    client=chroma_client,\n","    collection_name=\"marmikpandya\",\n","    embedding_function=ef_lc,\n",")\n","retriever = langchain_chroma.as_retriever()\n","\n","from langchain.chains import create_retrieval_chain\n","\n","from langchain.chains.combine_documents import create_stuff_documents_chain\n","from langchain_core.prompts import ChatPromptTemplate\n","prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n","\n","<context>\n","{context}\n","</context>\n","\n","Question: {input}\"\"\")\n","\n","document_chain = create_stuff_documents_chain(llm, prompt)\n","retrieval_chain = create_retrieval_chain(retriever, document_chain)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"ZmIe8Ui5nVBD","executionInfo":{"status":"error","timestamp":1717595427416,"user_tz":-210,"elapsed":6039,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"21dfa233-5974-469c-f755-7aa645f4b923"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Deleted existing collection: marmikpandya\n"]},{"output_type":"error","ename":"TypeError","evalue":"Expected a Runnable, callable or dict.Instead got an unsupported type: <class '__main__.LLM'>","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-8d486f2cda7c>\u001b[0m in \u001b[0;36m<cell line: 74>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLLM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhf_pipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m \u001b[0mdocument_chain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_stuff_documents_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0mretrieval_chain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_retrieval_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretriever\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument_chain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/combine_documents/stuff.py\u001b[0m in \u001b[0;36mcreate_stuff_documents_chain\u001b[0;34m(llm, prompt, output_parser, document_prompt, document_separator)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     return (\n\u001b[0;32m---> 84\u001b[0;31m         RunnablePassthrough.assign(**{DOCUMENTS_KEY: format_docs}).with_config(\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0mrun_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"format_inputs\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m__or__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   2348\u001b[0m                 \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmiddle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2349\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2350\u001b[0;31m                 \u001b[0mcoerce_to_runnable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2351\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2352\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mcoerce_to_runnable\u001b[0;34m(thing)\u001b[0m\n\u001b[1;32m   4900\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnableParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4901\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4902\u001b[0;31m         raise TypeError(\n\u001b[0m\u001b[1;32m   4903\u001b[0m             \u001b[0;34mf\"Expected a Runnable, callable or dict.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4904\u001b[0m             \u001b[0;34mf\"Instead got an unsupported type: {type(thing)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Expected a Runnable, callable or dict.Instead got an unsupported type: <class '__main__.LLM'>"]}]},{"cell_type":"code","source":["context_data = [\n","    \"The capital of France is Paris. It is known for its art, culture, and cuisine.\",\n","    \"The Great Wall of China is one of the greatest wonders of the world.\",\n","    \"The Amazon rainforest is a moist broadleaf forest that covers most of the Amazon basin of South America.\",\n","    \"The Amazon rainforest is a moist broadleaf forest that covers most of the Amazon basin of South Asia.\"\n","]\n","\n","# collection = Collection(collection_name=\"qa_contexts\", model_name='all-MiniLM-L6-v2')\n","# collection = Collection(collection_name=\"qa_contexts\", model_name='paraphrase-MiniLM-L6-v2')\n","collection = Collection(collection_name=\"qa_contexts\", model_name='paraphrase-xlm-r-multilingual-v1')\n","# collection = Collection(collection_name=\"qa_contexts\", model_name='stsb-roberta-large')\n","\n","# Add contexts to the collection\n","collection.add_contexts(context_data)\n","\n","# Retrieve a context based on a question\n","question = \"What is the capital of France?\"\n","context = collection.retrieve_contexts(question)\n","print(f\"Retrieved context: {context}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AoDt7bZjB_kI","executionInfo":{"status":"ok","timestamp":1717528413495,"user_tz":-210,"elapsed":9035,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"70a1e3be-f2d6-4067-ebd2-3dfe5133663a"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Documents added to ChromaDB.\n","Retrieved context: ['The capital of France is Paris. It is known for its art, culture, and cuisine.']\n"]}]},{"cell_type":"code","source":["!pip install -q langchain_chroma langchain_community"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6C6QNGhoXgcH","executionInfo":{"status":"ok","timestamp":1717590461468,"user_tz":-210,"elapsed":16369,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}},"outputId":"9f4b6e44-804c-47e6-d58e-e8806e690dc0"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import logging\n","from sentence_transformers import SentenceTransformer\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel, T5Tokenizer, T5ForConditionalGeneration, BertTokenizer, BertForMaskedLM, DistilBertTokenizer, DistilBertForMaskedLM, RobertaTokenizer, RobertaForMaskedLM, GPTNeoForCausalLM\n","import torch\n","from chromadb import Client, Settings\n","from langchain.chains import create_retrieval_chain\n","# from langchain.llms import OpenAI\n","from langchain_chroma import Chroma\n","from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings"],"metadata":{"id":"zGb10OtRXcF7","executionInfo":{"status":"ok","timestamp":1717590466592,"user_tz":-210,"elapsed":1,"user":{"displayName":"mohammad mohammdian","userId":"16778632015796518458"}}},"execution_count":20,"outputs":[]}]}